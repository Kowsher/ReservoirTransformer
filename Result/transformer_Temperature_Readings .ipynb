{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJzRm-WPvth7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/IOT-temp 2.csv')\n",
        "\n",
        "df=df.drop(columns = ['id', 'room_id/id', 'noted_date'])\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "#df = imputer.fit_transform(df)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le1= LabelEncoder()\n",
        "\n",
        "\n",
        "df['out/in']= le1.fit_transform(df['out/in'])\n",
        "\n",
        "'''\n",
        "df=df.dropna()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le1 = LabelEncoder()\n",
        "le2 = LabelEncoder()\n",
        "'''\n",
        "\n",
        "\n",
        "#df['icon']= le.fit_transform(df['icon'])\n",
        "\n",
        "y = df['out/in'].values\n",
        "df=df.drop(columns = ['out/in'])\n",
        "X = df.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8AhP-1JwJ79"
      },
      "outputs": [],
      "source": [
        "\n",
        "y=y.reshape(-1, 1)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "X=np.concatenate((X[1:], y[0:-1]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDfNyxfrwL-3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X= sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjgmUHADwXIJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, y[1:], test_size=0.2, shuffle=False, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpxcgA6OwYmn"
      },
      "outputs": [],
      "source": [
        "x_train1 = x_train1.reshape((x_train1.shape[0], x_train1.shape[1], 1))\n",
        "x_test1 = x_test1.reshape((x_test1.shape[0], x_test1.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgwvxfOowa9b"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxqGaYRxwdER"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74pYOQhZwfhX"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "    #outputs = layers.Dense(1)(x)\n",
        "\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7KsIcGkwrHx",
        "outputId": "247542b9-38d7-4462-802b-59e4e754b0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 2, 1)]       0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 2, 1)        2           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 2, 1)        7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2, 1)         0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 2, 1)        0           ['dropout[0][0]',                \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 2, 4)         8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 2, 4)         0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 2, 1)         5           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 2, 1)        0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 2, 1)        7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 2, 1)         0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 2, 1)        0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 2, 4)         8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 2, 4)         0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2, 1)         5           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 2, 1)        0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 2, 1)        7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 2, 1)         0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 2, 1)        0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2, 4)         8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 2, 4)         0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 2, 1)         5           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 2, 1)        0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 2, 1)        7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 2, 1)         0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 2, 1)        0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 2, 1)        2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 2, 4)         8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 2, 4)         0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 2, 1)         5           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 2, 1)        0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 2)           0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          384         ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 29,386\n",
            "Trainable params: 29,386\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "input_shape = x_train1.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "'''\n",
        "model.compile(\n",
        "    loss=\"mean_absolute_error\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\"mean_absolute_error\"],\n",
        ")\n",
        "'''\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUdAP2aoz-Nl",
        "outputId": "5d632900-241d-46d8-9e65-a9149a70e026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "611/611 [==============================] - 14s 23ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 2/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 3/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.5099\n",
            "Epoch 4/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6497 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 5/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 6/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 7/100\n",
            "611/611 [==============================] - 8s 14ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.6578\n",
            "Epoch 8/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 9/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 10/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.8893 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 11/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 12/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 13/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6530 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 14/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2233 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 15/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 16/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 17/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 18/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 19/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 20/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 21/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 22/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 23/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 24/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2223 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.5918\n",
            "Epoch 25/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 26/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.5099\n",
            "Epoch 27/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 28/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 29/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6533 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 30/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 31/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 32/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.6492\n",
            "Epoch 33/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 34/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 35/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 36/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 37/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 38/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 39/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2230 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 40/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8883 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 41/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 42/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 43/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 44/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 45/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 46/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 47/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 48/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 49/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 50/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 51/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.5224\n",
            "Epoch 52/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.8893 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6127\n",
            "Epoch 53/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6526 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 54/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 55/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 56/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 57/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 58/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.5309\n",
            "Epoch 59/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 60/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 61/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6003\n",
            "Epoch 62/100\n",
            "611/611 [==============================] - 8s 13ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.6003\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)]\n",
        "\n",
        "history=model.fit(\n",
        "    x_train1,\n",
        "    y_train1,\n",
        "    validation_data=(x_test1, y_test1),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueh9al7Gf26I"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIz0Rwc1ftLk",
        "outputId": "fde0e1a8-210b-4165-960c-cf8d4a8f3830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.6492495261513243\n",
            "f1_score 0.6884753628463532\n",
            "jaccard_score 0.5249427600083258\n",
            "roc_auc_score 0.6464247508949346\n",
            "precision_score 0.6322914925622597\n",
            "recall_score 0.7556176969939079\n"
          ]
        }
      ],
      "source": [
        "#testing prediction\n",
        "ypred1=model.predict(x_test1)\n",
        "ypred=[]\n",
        "#testing prediction\n",
        "for i in ypred1:\n",
        "    if i[0]>i[1]:\n",
        "        ypred.append(0)\n",
        "    else:\n",
        "        ypred.append(1)\n",
        "from sklearn.metrics import accuracy_score, f1_score,  jaccard_score, roc_auc_score, precision_score, recall_score\n",
        "print('accuracy', accuracy_score(ypred, y_test1))\n",
        "\n",
        "\n",
        "\n",
        "print('f1_score', f1_score(ypred, y_test1))\n",
        "\n",
        "\n",
        "\n",
        "print('jaccard_score', jaccard_score(ypred, y_test1))\n",
        "print('roc_auc_score', roc_auc_score(ypred, y_test1))\n",
        "print('precision_score', precision_score(ypred, y_test1))\n",
        "\n",
        "print('recall_score', recall_score(ypred, y_test1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BqSdi172JdD",
        "outputId": "78f11e31-db00-4615-972d-69b3dbae8576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8881717125147277\n",
            "f1_score 0.9345309500959693\n",
            "jaccard_score 0.8771075520027022\n",
            "roc_auc_score 0.8090993744458292\n",
            "precision_score 0.9544681828623938\n",
            "recall_score 0.9154095856406339\n"
          ]
        }
      ],
      "source": [
        "#ttraining prediction\n",
        "xpred1=model.predict(x_train1)\n",
        "xpred=[]\n",
        "\n",
        "for i in xpred1:\n",
        "    if i[0]>i[1]:\n",
        "        xpred.append(0)\n",
        "    else:\n",
        "        xpred.append(1)\n",
        "from sklearn.metrics import accuracy_score, f1_score,  jaccard_score, roc_auc_score, precision_score, recall_score\n",
        "print('accuracy', accuracy_score(xpred, y_train1))\n",
        "\n",
        "\n",
        "\n",
        "print('f1_score', f1_score(xpred, y_train1))\n",
        "\n",
        "\n",
        "\n",
        "print('jaccard_score', jaccard_score(xpred, y_train1))\n",
        "print('roc_auc_score', roc_auc_score(xpred, y_train1))\n",
        "print('precision_score', precision_score(xpred, y_train1))\n",
        "\n",
        "print('recall_score', recall_score(xpred, y_train1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XMSQfLXdi6da"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer-Temperature Readings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}