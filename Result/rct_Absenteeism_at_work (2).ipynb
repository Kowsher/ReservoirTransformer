{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M2icok5AYzvS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Absenteeism_at_work.csv', sep =';')\n",
        "\n",
        "#df=df.drop(columns = ['date'])\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "#df = imputer.fit_transform(df)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le1= LabelEncoder()\n",
        "le2= LabelEncoder()\n",
        "le3= LabelEncoder()\n",
        "\n",
        "'''\n",
        "df=df.dropna()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le1 = LabelEncoder()\n",
        "le2 = LabelEncoder()\n",
        "'''\n",
        "\n",
        "\n",
        "#df['icon']= le.fit_transform(df['icon'])\n",
        "\n",
        "y = df['Social drinker'].values\n",
        "df=df.drop(columns = ['Social drinker'])\n",
        "X = df.values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "guBeZhMnFYBm",
        "outputId": "5be3cb91-1e8d-47c2-e5dd-542e6b9733f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
              "0    11                  26                 7                3        1   \n",
              "1    36                   0                 7                3        1   \n",
              "2     3                  23                 7                4        1   \n",
              "3     7                   7                 7                5        1   \n",
              "4    11                  23                 7                5        1   \n",
              "..   ..                 ...               ...              ...      ...   \n",
              "735  11                  14                 7                3        1   \n",
              "736   1                  11                 7                3        1   \n",
              "737   4                   0                 0                3        1   \n",
              "738   8                   0                 0                4        2   \n",
              "739  35                   0                 0                6        3   \n",
              "\n",
              "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
              "0                       289                               36            13   \n",
              "1                       118                               13            18   \n",
              "2                       179                               51            18   \n",
              "3                       279                                5            14   \n",
              "4                       289                               36            13   \n",
              "..                      ...                              ...           ...   \n",
              "735                     289                               36            13   \n",
              "736                     235                               11            14   \n",
              "737                     118                               14            13   \n",
              "738                     231                               35            14   \n",
              "739                     179                               45            14   \n",
              "\n",
              "     Age  Work load Average/day   ...  Disciplinary failure  Education  Son  \\\n",
              "0     33                 239.554  ...                     0          1    2   \n",
              "1     50                 239.554  ...                     1          1    1   \n",
              "2     38                 239.554  ...                     0          1    0   \n",
              "3     39                 239.554  ...                     0          1    2   \n",
              "4     33                 239.554  ...                     0          1    2   \n",
              "..   ...                     ...  ...                   ...        ...  ...   \n",
              "735   33                 264.604  ...                     0          1    2   \n",
              "736   37                 264.604  ...                     0          3    1   \n",
              "737   40                 271.219  ...                     0          1    1   \n",
              "738   39                 271.219  ...                     0          1    2   \n",
              "739   53                 271.219  ...                     0          1    1   \n",
              "\n",
              "     Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \\\n",
              "0                 1              0    1      90     172               30   \n",
              "1                 1              0    0      98     178               31   \n",
              "2                 1              0    0      89     170               31   \n",
              "3                 1              1    0      68     168               24   \n",
              "4                 1              0    1      90     172               30   \n",
              "..              ...            ...  ...     ...     ...              ...   \n",
              "735               1              0    1      90     172               30   \n",
              "736               0              0    1      88     172               29   \n",
              "737               1              0    8      98     170               34   \n",
              "738               1              0    2     100     170               35   \n",
              "739               0              0    1      77     175               25   \n",
              "\n",
              "     Absenteeism time in hours  \n",
              "0                            4  \n",
              "1                            0  \n",
              "2                            2  \n",
              "3                            4  \n",
              "4                            2  \n",
              "..                         ...  \n",
              "735                          8  \n",
              "736                          4  \n",
              "737                          0  \n",
              "738                          0  \n",
              "739                          0  \n",
              "\n",
              "[740 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e9516ab-0d14-48a3-8f2d-3f016b34ecdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Reason for absence</th>\n",
              "      <th>Month of absence</th>\n",
              "      <th>Day of the week</th>\n",
              "      <th>Seasons</th>\n",
              "      <th>Transportation expense</th>\n",
              "      <th>Distance from Residence to Work</th>\n",
              "      <th>Service time</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work load Average/day</th>\n",
              "      <th>...</th>\n",
              "      <th>Disciplinary failure</th>\n",
              "      <th>Education</th>\n",
              "      <th>Son</th>\n",
              "      <th>Social drinker</th>\n",
              "      <th>Social smoker</th>\n",
              "      <th>Pet</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Body mass index</th>\n",
              "      <th>Absenteeism time in hours</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>289</td>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>239.554</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>172</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>118</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>239.554</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>178</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>179</td>\n",
              "      <td>51</td>\n",
              "      <td>18</td>\n",
              "      <td>38</td>\n",
              "      <td>239.554</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>170</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>279</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>39</td>\n",
              "      <td>239.554</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>168</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>289</td>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>239.554</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>172</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>289</td>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>264.604</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>172</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>235</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>37</td>\n",
              "      <td>264.604</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>172</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>118</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>40</td>\n",
              "      <td>271.219</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>98</td>\n",
              "      <td>170</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>231</td>\n",
              "      <td>35</td>\n",
              "      <td>14</td>\n",
              "      <td>39</td>\n",
              "      <td>271.219</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>170</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>179</td>\n",
              "      <td>45</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>271.219</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>175</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>740 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e9516ab-0d14-48a3-8f2d-3f016b34ecdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e9516ab-0d14-48a3-8f2d-3f016b34ecdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e9516ab-0d14-48a3-8f2d-3f016b34ecdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "CgyrLr_T-2Ok",
        "outputId": "834b274e-42df-4db7-eee3-012996241fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(594, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_82uIQCFdziZ",
        "outputId": "139270ac-a1d9-40a5-d0e1-e58dd4fc1bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 320, 1: 420})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Rn2VoK1owI5"
      },
      "outputs": [],
      "source": [
        "\n",
        "y=y.reshape(-1, 1)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "X=np.concatenate((X[1:], y[0:-1]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxWNccXgu12l",
        "outputId": "646e6d17-54f8-4fb7-d746-8da2bd401dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.5)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=ca3a93065eed78aa5d0ea48fb9fad711163557fc5de8130e023212e86f7fb7cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8iIZ1105tFnf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X= sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl0SFJ5WtbBP",
        "outputId": "01728dcd-6cb6-4911-c27d-d3e293eac374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyrcn\n",
            "  Downloading PyRCN-0.0.16.post1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 4.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyrcn\n",
            "Successfully installed pyrcn-0.0.16.post1\n"
          ]
        }
      ],
      "source": [
        "pip install pyrcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gEPWGptbuTYk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, y[1:], test_size=0.2, shuffle=False, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDAxxhLupYK6",
        "outputId": "9923f053-6c2d-4ccc-ba9b-78f74b0df26a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(591, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_train1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1rOeQ0-ptl_G"
      },
      "outputs": [],
      "source": [
        "from pyrcn.base.blocks import InputToNode\n",
        "from sklearn . datasets import make_blobs\n",
        "# Generate a toy dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2tShY5ktnrN",
        "outputId": "2cc1d918-3ad5-47cb-9998-4d304c160a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:77: FutureWarning: Pass hidden_layer_size=22 as keyword args. From version 1.1 (renaming of 0.26) passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_to_node = InputToNode (22, input_activation='relu',input_scaling =1.0 )\n",
        "\n",
        "\n",
        "x_train= input_to_node.fit_transform (x_train1)\n",
        "x_test= input_to_node.transform (x_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDw3vyTRuB-o",
        "outputId": "0f81c49e-c0ba-4011-e9f0-17ca0475e343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:77: FutureWarning: Pass hidden_layer_size=22 as keyword args. From version 1.1 (renaming of 0.26) passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from pyrcn.base.blocks import NodeToNode\n",
        "node_to_node = NodeToNode (22, reservoir_activation='relu', spectral_radius =1.0 , leakage =0.8 ,bidirectional = False )\n",
        "x_train=node_to_node . fit_transform(x_train)\n",
        "x_test= node_to_node.transform (x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b-dqEbXtuCpY"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "x_train1 = x_train1.reshape((x_train1.shape[0], x_train1.shape[1], 1))\n",
        "x_test1 = x_test1.reshape((x_test1.shape[0], x_test1.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qi0MhVmsuswU"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NX3w9IqBuuZ-"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HsU6bO-PuvqD"
      },
      "outputs": [],
      "source": [
        "from keras_self_attention import SeqSelfAttention\n",
        "def build_model(\n",
        "    input_shapey,\n",
        "    input_shapez,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputsy = keras.Input(shape=input_shapey)\n",
        "    inputsz = keras.Input(shape=input_shapez)\n",
        "    y = inputsy\n",
        "    z= inputsz\n",
        "\n",
        "    #z=layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(z)\n",
        "\n",
        "    #y=layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(y)\n",
        "\n",
        "    z=SeqSelfAttention()(z)\n",
        "\n",
        "    #y=SeqSelfAttention()(y)\n",
        "\n",
        "\n",
        "\n",
        "    x=layers.Concatenate(axis=1)([y, z])\n",
        "    #x=layers.Add()([inputsy, inputsz])\n",
        "\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "    #outputs = layers.Dense(1)(x)\n",
        "    return keras.Model([inputsy,inputsz], outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Hu3CH4vZzu",
        "outputId": "e65ef4d2-a52b-45d2-8074-aa3c9c6f7646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 22, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 21, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " seq_self_attention (SeqSelfAtt  (None, 22, 1)       129         ['input_2[0][0]']                \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 43, 1)        0           ['input_1[0][0]',                \n",
            "                                                                  'seq_self_attention[0][0]']     \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 43, 1)       2           ['concatenate[0][0]']            \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 43, 1)       7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 43, 1)        0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 43, 1)       0           ['dropout[0][0]',                \n",
            " da)                                                              'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 43, 4)        8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 43, 4)        0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 43, 1)        5           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 43, 1)       0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 43, 1)       7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 43, 1)        0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 43, 1)       0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 43, 4)        8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 43, 4)        0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 43, 1)        5           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 43, 1)       0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 43, 1)       7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 43, 1)        0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 43, 1)       0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 43, 4)        8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 43, 4)        0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 43, 1)        5           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 43, 1)       0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 43, 1)       7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 43, 1)        0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 43, 1)       0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 43, 1)       2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 43, 4)        8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 43, 4)        0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 43, 1)        5           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 43, 1)       0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 43)          0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          5632        ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,763\n",
            "Trainable params: 34,763\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shapey = x_train1.shape[1:]\n",
        "input_shapez = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shapey,\n",
        "    input_shapez,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "'''\n",
        "model.compile(\n",
        "    loss=\"mean_absolute_error\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\"mean_absolute_error\"],\n",
        ")\n",
        "'''\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jta9P_Q3vkrc",
        "outputId": "6588f665-6e1b-47d9-ed60-10438d4c0768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "5/5 [==============================] - 6s 197ms/step - loss: 1.1257 - accuracy: 0.5347 - val_loss: 0.4653 - val_accuracy: 0.7568\n",
            "Epoch 2/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6317 - accuracy: 0.6887 - val_loss: 0.4514 - val_accuracy: 0.7973\n",
            "Epoch 3/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.4431 - accuracy: 0.7851 - val_loss: 0.4220 - val_accuracy: 0.8176\n",
            "Epoch 4/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.3669 - accuracy: 0.8545 - val_loss: 0.3794 - val_accuracy: 0.8378\n",
            "Epoch 5/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2923 - accuracy: 0.8951 - val_loss: 0.3681 - val_accuracy: 0.8581\n",
            "Epoch 6/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2280 - accuracy: 0.9222 - val_loss: 0.3549 - val_accuracy: 0.8716\n",
            "Epoch 7/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1628 - accuracy: 0.9459 - val_loss: 0.3763 - val_accuracy: 0.8716\n",
            "Epoch 8/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1301 - accuracy: 0.9543 - val_loss: 0.4044 - val_accuracy: 0.8784\n",
            "Epoch 9/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1212 - accuracy: 0.9662 - val_loss: 0.4194 - val_accuracy: 0.8851\n",
            "Epoch 10/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1033 - accuracy: 0.9662 - val_loss: 0.4038 - val_accuracy: 0.8919\n",
            "Epoch 11/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0700 - accuracy: 0.9797 - val_loss: 0.3750 - val_accuracy: 0.8986\n",
            "Epoch 12/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.3443 - val_accuracy: 0.9122\n",
            "Epoch 13/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0414 - accuracy: 0.9932 - val_loss: 0.3674 - val_accuracy: 0.9257\n",
            "Epoch 14/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0385 - accuracy: 0.9915 - val_loss: 0.4161 - val_accuracy: 0.9257\n",
            "Epoch 15/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.4549 - val_accuracy: 0.9257\n",
            "Epoch 16/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0251 - accuracy: 0.9949 - val_loss: 0.4905 - val_accuracy: 0.9257\n",
            "Epoch 17/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0283 - accuracy: 0.9966 - val_loss: 0.4801 - val_accuracy: 0.9257\n",
            "Epoch 18/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9257\n",
            "Epoch 19/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0234 - accuracy: 0.9966 - val_loss: 0.4486 - val_accuracy: 0.9257\n",
            "Epoch 20/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.4216 - val_accuracy: 0.9257\n",
            "Epoch 21/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.4480 - val_accuracy: 0.9257\n",
            "Epoch 22/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.4777 - val_accuracy: 0.9257\n",
            "Epoch 23/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.4549 - val_accuracy: 0.9257\n",
            "Epoch 24/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9527\n",
            "Epoch 25/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9662\n",
            "Epoch 26/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9662\n",
            "Epoch 27/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4297 - val_accuracy: 0.9662\n",
            "Epoch 28/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9662\n",
            "Epoch 29/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.4471 - val_accuracy: 0.9662\n",
            "Epoch 30/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9662\n",
            "Epoch 31/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.4475 - val_accuracy: 0.9662\n",
            "Epoch 32/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9662\n",
            "Epoch 33/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.4588 - val_accuracy: 0.9662\n",
            "Epoch 34/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9662\n",
            "Epoch 35/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0064 - accuracy: 0.9966 - val_loss: 0.4683 - val_accuracy: 0.9662\n",
            "Epoch 36/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9595\n",
            "Epoch 37/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9527\n",
            "Epoch 38/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9527\n",
            "Epoch 39/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.4857 - val_accuracy: 0.9527\n",
            "Epoch 40/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.4883 - val_accuracy: 0.9527\n",
            "Epoch 41/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.4900 - val_accuracy: 0.9662\n",
            "Epoch 42/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.4851 - val_accuracy: 0.9662\n",
            "Epoch 43/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9662\n",
            "Epoch 44/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.4801 - val_accuracy: 0.9662\n",
            "Epoch 45/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9662\n",
            "Epoch 46/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9662\n",
            "Epoch 47/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9662\n",
            "Epoch 48/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.4947 - val_accuracy: 0.9662\n",
            "Epoch 49/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.4688 - val_accuracy: 0.9662\n",
            "Epoch 50/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.4607 - val_accuracy: 0.9662\n",
            "Epoch 51/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.4581 - val_accuracy: 0.9662\n",
            "Epoch 52/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9662\n",
            "Epoch 53/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9662\n",
            "Epoch 54/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.4520 - val_accuracy: 0.9662\n",
            "Epoch 55/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9662\n",
            "Epoch 56/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9595\n",
            "Epoch 57/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9662\n",
            "Epoch 58/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9662\n",
            "Epoch 59/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9662\n",
            "Epoch 60/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9662\n",
            "Epoch 61/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9662\n",
            "Epoch 62/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9662\n",
            "Epoch 63/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9662\n",
            "Epoch 64/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9662\n",
            "Epoch 65/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.0842e-04 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.9662\n",
            "Epoch 66/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9595\n",
            "Epoch 67/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.9595\n",
            "Epoch 68/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.5523 - val_accuracy: 0.9662\n",
            "Epoch 69/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.3772e-04 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 0.9662\n",
            "Epoch 70/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.9662\n",
            "Epoch 71/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.9662\n",
            "Epoch 72/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.5979e-04 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.9662\n",
            "Epoch 73/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.9662\n",
            "Epoch 74/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.9662\n",
            "Epoch 75/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9662\n",
            "Epoch 76/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 0.6084 - val_accuracy: 0.9662\n",
            "Epoch 77/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 7.4362e-04 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.9662\n",
            "Epoch 78/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 6.2902e-04 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9662\n",
            "Epoch 79/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.9662\n",
            "Epoch 80/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.9662\n",
            "Epoch 81/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 6.2128e-04 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9662\n",
            "Epoch 82/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 6.9575e-04 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.9662\n",
            "Epoch 83/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.6219 - val_accuracy: 0.9662\n",
            "Epoch 84/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.9662\n",
            "Epoch 85/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.6072 - val_accuracy: 0.9662\n",
            "Epoch 86/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.9662\n",
            "Epoch 87/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 9.6073e-04 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.9662\n",
            "Epoch 88/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.9662\n",
            "Epoch 89/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.9662\n",
            "Epoch 90/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 8.2829e-04 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.9662\n",
            "Epoch 91/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 8.2415e-04 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.9662\n",
            "Epoch 92/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 9.9489e-04 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.9662\n",
            "Epoch 93/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 6.9032e-04 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9662\n",
            "Epoch 94/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9662\n",
            "Epoch 95/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9662\n",
            "Epoch 96/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.9086e-04 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9662\n",
            "Epoch 97/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.0305e-04 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9662\n",
            "Epoch 98/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.6085 - val_accuracy: 0.9662\n",
            "Epoch 99/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.4552e-04 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.9662\n",
            "Epoch 100/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.4523e-04 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.9662\n",
            "Epoch 101/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.9662\n",
            "Epoch 102/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.3764e-04 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.9662\n",
            "Epoch 103/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.9662\n",
            "Epoch 104/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 0.9662\n",
            "Epoch 105/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.6849e-04 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.9662\n",
            "Epoch 106/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 3.1507e-04 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.9662\n",
            "Epoch 107/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 9.0385e-04 - accuracy: 1.0000 - val_loss: 0.6319 - val_accuracy: 0.9662\n",
            "Epoch 108/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 0.6352 - val_accuracy: 0.9662\n",
            "Epoch 109/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 8.7145e-04 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.9662\n",
            "Epoch 110/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 8.9812e-04 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.9662\n",
            "Epoch 111/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.6366 - val_accuracy: 0.9662\n",
            "Epoch 112/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.6372 - val_accuracy: 0.9662\n",
            "Epoch 113/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 0.9662\n",
            "Epoch 114/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 6.8904e-04 - accuracy: 1.0000 - val_loss: 0.6506 - val_accuracy: 0.9662\n",
            "Epoch 115/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.9662\n",
            "Epoch 116/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 3.0103e-04 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.9662\n",
            "Epoch 117/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 5.7467e-04 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.9662\n",
            "Epoch 118/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.9662\n",
            "Epoch 119/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.6780 - val_accuracy: 0.9662\n",
            "Epoch 120/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.9662\n",
            "Epoch 121/2000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.9662\n",
            "Epoch 122/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.9662\n",
            "Epoch 123/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.9662\n",
            "Epoch 124/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 0.6925 - val_accuracy: 0.9662\n",
            "Epoch 125/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.7160 - val_accuracy: 0.9662\n",
            "Epoch 126/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 9.1099e-04 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.9662\n",
            "Epoch 127/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.9662\n",
            "Epoch 128/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 6.2248e-04 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.9662\n",
            "Epoch 129/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.9662\n",
            "Epoch 130/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.9662\n",
            "Epoch 131/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.8850e-04 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.9662\n",
            "Epoch 132/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.9662\n",
            "Epoch 133/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.9662\n",
            "Epoch 134/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.7112e-04 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.9662\n",
            "Epoch 135/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 5.0603e-04 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.9662\n",
            "Epoch 136/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.5818e-04 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.9662\n",
            "Epoch 137/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.9662\n",
            "Epoch 138/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.6150e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.9662\n",
            "Epoch 139/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.9662\n",
            "Epoch 140/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.9701e-04 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.9662\n",
            "Epoch 141/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 3.5841e-04 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.9662\n",
            "Epoch 142/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.2931e-04 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.9662\n",
            "Epoch 143/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 3.3854e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.9662\n",
            "Epoch 144/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.9662\n",
            "Epoch 145/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.9662\n",
            "Epoch 146/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.1184e-04 - accuracy: 1.0000 - val_loss: 0.7817 - val_accuracy: 0.9662\n",
            "Epoch 147/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.7153e-04 - accuracy: 1.0000 - val_loss: 0.7875 - val_accuracy: 0.9662\n",
            "Epoch 148/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.9662\n",
            "Epoch 149/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.9922e-04 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9662\n",
            "Epoch 150/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.0633e-04 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.9662\n",
            "Epoch 151/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.9948e-04 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.9662\n",
            "Epoch 152/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 7.9083e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.9662\n",
            "Epoch 153/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.9662\n",
            "Epoch 154/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.6045e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.9662\n",
            "Epoch 155/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 0.7038 - val_accuracy: 0.9662\n",
            "Epoch 156/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.9058e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.9662\n",
            "Epoch 157/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 8.5111e-04 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.9662\n",
            "Epoch 158/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 3.1202e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9662\n",
            "Epoch 159/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.7289e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.9662\n",
            "Epoch 160/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 4.5012e-04 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.9662\n",
            "Epoch 161/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 6.6173e-04 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.9662\n",
            "Epoch 162/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 2.4569e-04 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.9662\n",
            "Epoch 163/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 3.3876e-04 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.9662\n",
            "Epoch 164/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 5.8935e-04 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.9662\n",
            "Epoch 165/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.3941e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.9662\n",
            "Epoch 166/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 2.0209e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.9662\n",
            "Epoch 167/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.2783e-04 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.9662\n",
            "Epoch 168/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 4.0262e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.9662\n",
            "Epoch 169/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 4.5259e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.9662\n",
            "Epoch 170/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 5.0275e-04 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.9662\n",
            "Epoch 171/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 3.3977e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.9662\n",
            "Epoch 172/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.1165e-04 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.9662\n",
            "Epoch 173/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8771e-04 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.9662\n",
            "Epoch 174/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.5941e-04 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.9662\n",
            "Epoch 175/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.2426e-04 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9662\n",
            "Epoch 176/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.9298e-04 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.9662\n",
            "Epoch 177/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 3.5142e-04 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.9662\n",
            "Epoch 178/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.9871e-04 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.9662\n",
            "Epoch 179/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.5340e-04 - accuracy: 1.0000 - val_loss: 0.7808 - val_accuracy: 0.9662\n",
            "Epoch 180/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 3.7202e-04 - accuracy: 1.0000 - val_loss: 0.7751 - val_accuracy: 0.9662\n",
            "Epoch 181/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 4.9632e-04 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.9662\n",
            "Epoch 182/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 3.7588e-04 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.9662\n",
            "Epoch 183/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.9662\n",
            "Epoch 184/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.1736e-04 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.9662\n",
            "Epoch 185/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 3.3794e-04 - accuracy: 1.0000 - val_loss: 0.7802 - val_accuracy: 0.9662\n",
            "Epoch 186/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8157e-04 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.9662\n",
            "Epoch 187/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 6.2658e-04 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.9662\n",
            "Epoch 188/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.9540e-04 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.9662\n",
            "Epoch 189/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.9254e-04 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.9662\n",
            "Epoch 190/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.5323e-04 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.9662\n",
            "Epoch 191/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.1767e-04 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.9662\n",
            "Epoch 192/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.8599e-04 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.9662\n",
            "Epoch 193/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 4.9823e-04 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.9662\n",
            "Epoch 194/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 6.5706e-04 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.9662\n",
            "Epoch 195/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.7202e-04 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.9662\n",
            "Epoch 196/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.2932e-04 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.9662\n",
            "Epoch 197/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.1051e-05 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.9662\n",
            "Epoch 198/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7530e-04 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.9662\n",
            "Epoch 199/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7704e-04 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.9662\n",
            "Epoch 200/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.8997e-04 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.9662\n",
            "Epoch 201/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.4048e-04 - accuracy: 1.0000 - val_loss: 0.8208 - val_accuracy: 0.9662\n",
            "Epoch 202/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0946e-04 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.9662\n",
            "Epoch 203/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.1818e-04 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.9662\n",
            "Epoch 204/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0649e-04 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.9662\n",
            "Epoch 205/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 9.3797e-05 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.9662\n",
            "Epoch 206/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.1977e-05 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.9662\n",
            "Epoch 207/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 2.7640e-04 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.9662\n",
            "Epoch 208/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 4.6520e-04 - accuracy: 1.0000 - val_loss: 0.8172 - val_accuracy: 0.9662\n",
            "Epoch 209/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.9457e-04 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.9662\n",
            "Epoch 210/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8164e-04 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.9662\n",
            "Epoch 211/2000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 0.8256 - val_accuracy: 0.9662\n",
            "Epoch 212/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 7.5865e-04 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.9662\n",
            "Epoch 213/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 7.9501e-04 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.9662\n",
            "Epoch 214/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8544 - val_accuracy: 0.9662\n",
            "Epoch 215/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 5.2560e-04 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.9662\n",
            "Epoch 216/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 5.3263e-04 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.9662\n",
            "Epoch 217/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.8467 - val_accuracy: 0.9662\n",
            "Epoch 218/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 6.9183e-04 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.9662\n",
            "Epoch 219/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 5.1962e-04 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.9662\n",
            "Epoch 220/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.9662\n",
            "Epoch 221/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 4.8432e-04 - accuracy: 1.0000 - val_loss: 0.8299 - val_accuracy: 0.9662\n",
            "Epoch 222/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.8023 - val_accuracy: 0.9662\n",
            "Epoch 223/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.9662\n",
            "Epoch 224/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 0.8612 - val_accuracy: 0.9662\n",
            "Epoch 225/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 8.5032e-04 - accuracy: 1.0000 - val_loss: 0.8766 - val_accuracy: 0.9662\n",
            "Epoch 226/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 6.9777e-04 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.9662\n",
            "Epoch 227/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 3.3881e-04 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.9662\n",
            "Epoch 228/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 3.8277e-04 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.9662\n",
            "Epoch 229/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.8110e-04 - accuracy: 1.0000 - val_loss: 0.8499 - val_accuracy: 0.9662\n",
            "Epoch 230/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.3736e-04 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.9662\n",
            "Epoch 231/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 6.8740e-04 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.9662\n",
            "Epoch 232/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.8109e-04 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.9662\n",
            "Epoch 233/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 6.1283e-05 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.9662\n",
            "Epoch 234/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.9421e-04 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.9662\n",
            "Epoch 235/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.2319e-04 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.9662\n",
            "Epoch 236/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.9662\n",
            "Epoch 237/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9662\n",
            "Epoch 238/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.9662\n",
            "Epoch 239/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 5.9884e-04 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.9662\n",
            "Epoch 240/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.8348e-04 - accuracy: 1.0000 - val_loss: 0.8382 - val_accuracy: 0.9662\n",
            "Epoch 241/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 3.4931e-04 - accuracy: 1.0000 - val_loss: 0.8575 - val_accuracy: 0.9662\n",
            "Epoch 242/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 0.9983 - val_loss: 0.9623 - val_accuracy: 0.9662\n",
            "Epoch 243/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.9076 - val_accuracy: 0.9662\n",
            "Epoch 244/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.9662\n",
            "Epoch 245/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 9.3713e-04 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.9527\n",
            "Epoch 246/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.7759 - accuracy: 0.8849 - val_loss: 100.7155 - val_accuracy: 0.4865\n",
            "Epoch 247/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 35.5014 - accuracy: 0.6176 - val_loss: 1.8838 - val_accuracy: 0.8108\n",
            "Epoch 248/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 20.1661 - accuracy: 0.5347 - val_loss: 6.9406 - val_accuracy: 0.6622\n",
            "Epoch 249/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.2946 - accuracy: 0.6294 - val_loss: 3.0564 - val_accuracy: 0.5608\n",
            "Epoch 250/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 4.4923 - accuracy: 0.6210 - val_loss: 1.1154 - val_accuracy: 0.6486\n",
            "Epoch 251/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.4294 - accuracy: 0.6430 - val_loss: 0.7328 - val_accuracy: 0.7365\n",
            "Epoch 252/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.8641 - accuracy: 0.6311 - val_loss: 0.5666 - val_accuracy: 0.7432\n",
            "Epoch 253/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6127 - accuracy: 0.6684 - val_loss: 0.5526 - val_accuracy: 0.7500\n",
            "Epoch 254/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5312 - accuracy: 0.7462 - val_loss: 0.4974 - val_accuracy: 0.7973\n",
            "Epoch 255/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4846 - accuracy: 0.8003 - val_loss: 0.4177 - val_accuracy: 0.8311\n",
            "Epoch 256/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4213 - accuracy: 0.8020 - val_loss: 0.4096 - val_accuracy: 0.8378\n",
            "Epoch 257/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3849 - accuracy: 0.8460 - val_loss: 0.3929 - val_accuracy: 0.8446\n",
            "Epoch 258/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3473 - accuracy: 0.8646 - val_loss: 0.3930 - val_accuracy: 0.8649\n",
            "Epoch 259/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3785 - accuracy: 0.8646 - val_loss: 0.3667 - val_accuracy: 0.8581\n",
            "Epoch 260/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3514 - accuracy: 0.8748 - val_loss: 0.3926 - val_accuracy: 0.8514\n",
            "Epoch 261/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3166 - accuracy: 0.8917 - val_loss: 0.3830 - val_accuracy: 0.8581\n",
            "Epoch 262/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2766 - accuracy: 0.8866 - val_loss: 0.3802 - val_accuracy: 0.8311\n",
            "Epoch 263/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2953 - accuracy: 0.8900 - val_loss: 0.3554 - val_accuracy: 0.8716\n",
            "Epoch 264/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2891 - accuracy: 0.9137 - val_loss: 0.3572 - val_accuracy: 0.8514\n",
            "Epoch 265/2000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.2447 - accuracy: 0.9306 - val_loss: 0.3385 - val_accuracy: 0.8919\n",
            "Epoch 266/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2397 - accuracy: 0.9222 - val_loss: 0.3544 - val_accuracy: 0.8784\n",
            "Epoch 267/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2158 - accuracy: 0.9306 - val_loss: 0.3540 - val_accuracy: 0.8784\n",
            "Epoch 268/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2346 - accuracy: 0.9103 - val_loss: 0.3399 - val_accuracy: 0.8851\n",
            "Epoch 269/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.2390 - accuracy: 0.9239 - val_loss: 0.3259 - val_accuracy: 0.8986\n",
            "Epoch 270/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2273 - accuracy: 0.9137 - val_loss: 0.3630 - val_accuracy: 0.8851\n",
            "Epoch 271/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1922 - accuracy: 0.9425 - val_loss: 0.3961 - val_accuracy: 0.8784\n",
            "Epoch 272/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1977 - accuracy: 0.9239 - val_loss: 0.3891 - val_accuracy: 0.8784\n",
            "Epoch 273/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1931 - accuracy: 0.9306 - val_loss: 0.3610 - val_accuracy: 0.8851\n",
            "Epoch 274/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1777 - accuracy: 0.9391 - val_loss: 0.3451 - val_accuracy: 0.8851\n",
            "Epoch 275/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.1901 - accuracy: 0.9357 - val_loss: 0.3735 - val_accuracy: 0.8784\n",
            "Epoch 276/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1750 - accuracy: 0.9543 - val_loss: 0.3676 - val_accuracy: 0.8851\n",
            "Epoch 277/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1869 - accuracy: 0.9391 - val_loss: 0.3400 - val_accuracy: 0.8919\n",
            "Epoch 278/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1752 - accuracy: 0.9425 - val_loss: 0.3568 - val_accuracy: 0.8784\n",
            "Epoch 279/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1827 - accuracy: 0.9408 - val_loss: 0.3915 - val_accuracy: 0.8784\n",
            "Epoch 280/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1459 - accuracy: 0.9594 - val_loss: 0.3731 - val_accuracy: 0.8851\n",
            "Epoch 281/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1411 - accuracy: 0.9560 - val_loss: 0.3615 - val_accuracy: 0.8919\n",
            "Epoch 282/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1485 - accuracy: 0.9442 - val_loss: 0.3911 - val_accuracy: 0.8784\n",
            "Epoch 283/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1653 - accuracy: 0.9459 - val_loss: 0.3707 - val_accuracy: 0.8851\n",
            "Epoch 284/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1385 - accuracy: 0.9594 - val_loss: 0.3454 - val_accuracy: 0.8919\n",
            "Epoch 285/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1426 - accuracy: 0.9543 - val_loss: 0.4141 - val_accuracy: 0.8851\n",
            "Epoch 286/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1382 - accuracy: 0.9662 - val_loss: 0.3948 - val_accuracy: 0.8784\n",
            "Epoch 287/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1349 - accuracy: 0.9543 - val_loss: 0.3685 - val_accuracy: 0.8919\n",
            "Epoch 288/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1526 - accuracy: 0.9425 - val_loss: 0.3605 - val_accuracy: 0.8919\n",
            "Epoch 289/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.1330 - accuracy: 0.9475 - val_loss: 0.3623 - val_accuracy: 0.8919\n",
            "Epoch 290/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1378 - accuracy: 0.9509 - val_loss: 0.3484 - val_accuracy: 0.8986\n",
            "Epoch 291/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1200 - accuracy: 0.9662 - val_loss: 0.3693 - val_accuracy: 0.8919\n",
            "Epoch 292/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1104 - accuracy: 0.9746 - val_loss: 0.3970 - val_accuracy: 0.8851\n",
            "Epoch 293/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1203 - accuracy: 0.9645 - val_loss: 0.3965 - val_accuracy: 0.8851\n",
            "Epoch 294/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1101 - accuracy: 0.9695 - val_loss: 0.3604 - val_accuracy: 0.9054\n",
            "Epoch 295/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1273 - accuracy: 0.9543 - val_loss: 0.4022 - val_accuracy: 0.8986\n",
            "Epoch 296/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1375 - accuracy: 0.9475 - val_loss: 0.4692 - val_accuracy: 0.8919\n",
            "Epoch 297/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.1193 - accuracy: 0.9526 - val_loss: 0.4922 - val_accuracy: 0.8851\n",
            "Epoch 298/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1209 - accuracy: 0.9543 - val_loss: 0.4487 - val_accuracy: 0.8851\n",
            "Epoch 299/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1081 - accuracy: 0.9594 - val_loss: 0.4302 - val_accuracy: 0.8986\n",
            "Epoch 300/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1221 - accuracy: 0.9611 - val_loss: 0.4034 - val_accuracy: 0.9122\n",
            "Epoch 301/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1038 - accuracy: 0.9645 - val_loss: 0.4277 - val_accuracy: 0.8986\n",
            "Epoch 302/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1009 - accuracy: 0.9763 - val_loss: 0.4365 - val_accuracy: 0.9054\n",
            "Epoch 303/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1116 - accuracy: 0.9679 - val_loss: 0.4193 - val_accuracy: 0.9122\n",
            "Epoch 304/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1095 - accuracy: 0.9662 - val_loss: 0.4339 - val_accuracy: 0.9054\n",
            "Epoch 305/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1023 - accuracy: 0.9577 - val_loss: 0.4688 - val_accuracy: 0.8919\n",
            "Epoch 306/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0935 - accuracy: 0.9662 - val_loss: 0.4840 - val_accuracy: 0.8986\n",
            "Epoch 307/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1056 - accuracy: 0.9628 - val_loss: 0.4549 - val_accuracy: 0.8986\n",
            "Epoch 308/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.1045 - accuracy: 0.9662 - val_loss: 0.4211 - val_accuracy: 0.8986\n",
            "Epoch 309/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0932 - accuracy: 0.9763 - val_loss: 0.4329 - val_accuracy: 0.8919\n",
            "Epoch 310/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1091 - accuracy: 0.9611 - val_loss: 0.4473 - val_accuracy: 0.8986\n",
            "Epoch 311/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0935 - accuracy: 0.9645 - val_loss: 0.4588 - val_accuracy: 0.8986\n",
            "Epoch 312/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0914 - accuracy: 0.9628 - val_loss: 0.4608 - val_accuracy: 0.9054\n",
            "Epoch 313/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0912 - accuracy: 0.9695 - val_loss: 0.4710 - val_accuracy: 0.8919\n",
            "Epoch 314/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0961 - accuracy: 0.9729 - val_loss: 0.4932 - val_accuracy: 0.9054\n",
            "Epoch 315/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0978 - accuracy: 0.9712 - val_loss: 0.4717 - val_accuracy: 0.8986\n",
            "Epoch 316/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0917 - accuracy: 0.9746 - val_loss: 0.4764 - val_accuracy: 0.8986\n",
            "Epoch 317/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0942 - accuracy: 0.9729 - val_loss: 0.4703 - val_accuracy: 0.9122\n",
            "Epoch 318/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0792 - accuracy: 0.9763 - val_loss: 0.4635 - val_accuracy: 0.9257\n",
            "Epoch 319/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0758 - accuracy: 0.9763 - val_loss: 0.4455 - val_accuracy: 0.9189\n",
            "Epoch 320/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0788 - accuracy: 0.9780 - val_loss: 0.4695 - val_accuracy: 0.9189\n",
            "Epoch 321/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0772 - accuracy: 0.9780 - val_loss: 0.4782 - val_accuracy: 0.9054\n",
            "Epoch 322/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0830 - accuracy: 0.9712 - val_loss: 0.4698 - val_accuracy: 0.9257\n",
            "Epoch 323/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0758 - accuracy: 0.9729 - val_loss: 0.4705 - val_accuracy: 0.9189\n",
            "Epoch 324/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0883 - accuracy: 0.9729 - val_loss: 0.4518 - val_accuracy: 0.9189\n",
            "Epoch 325/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0794 - accuracy: 0.9763 - val_loss: 0.4787 - val_accuracy: 0.9257\n",
            "Epoch 326/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0936 - accuracy: 0.9628 - val_loss: 0.4437 - val_accuracy: 0.9324\n",
            "Epoch 327/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0724 - accuracy: 0.9780 - val_loss: 0.4338 - val_accuracy: 0.9392\n",
            "Epoch 328/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0758 - accuracy: 0.9780 - val_loss: 0.4693 - val_accuracy: 0.9257\n",
            "Epoch 329/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0808 - accuracy: 0.9695 - val_loss: 0.4463 - val_accuracy: 0.9324\n",
            "Epoch 330/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0667 - accuracy: 0.9898 - val_loss: 0.4512 - val_accuracy: 0.9324\n",
            "Epoch 331/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0715 - accuracy: 0.9763 - val_loss: 0.4681 - val_accuracy: 0.9324\n",
            "Epoch 332/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0617 - accuracy: 0.9831 - val_loss: 0.5067 - val_accuracy: 0.9257\n",
            "Epoch 333/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0791 - accuracy: 0.9780 - val_loss: 0.4717 - val_accuracy: 0.9324\n",
            "Epoch 334/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0612 - accuracy: 0.9865 - val_loss: 0.4792 - val_accuracy: 0.9257\n",
            "Epoch 335/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0780 - accuracy: 0.9662 - val_loss: 0.4795 - val_accuracy: 0.9324\n",
            "Epoch 336/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0750 - accuracy: 0.9746 - val_loss: 0.4683 - val_accuracy: 0.9257\n",
            "Epoch 337/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0872 - accuracy: 0.9645 - val_loss: 0.4548 - val_accuracy: 0.9324\n",
            "Epoch 338/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0702 - accuracy: 0.9797 - val_loss: 0.4708 - val_accuracy: 0.9257\n",
            "Epoch 339/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0809 - accuracy: 0.9763 - val_loss: 0.4604 - val_accuracy: 0.9257\n",
            "Epoch 340/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0675 - accuracy: 0.9780 - val_loss: 0.4728 - val_accuracy: 0.9324\n",
            "Epoch 341/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0695 - accuracy: 0.9814 - val_loss: 0.4952 - val_accuracy: 0.9257\n",
            "Epoch 342/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.5253 - val_accuracy: 0.9257\n",
            "Epoch 343/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0615 - accuracy: 0.9865 - val_loss: 0.4917 - val_accuracy: 0.9324\n",
            "Epoch 344/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0670 - accuracy: 0.9814 - val_loss: 0.4657 - val_accuracy: 0.9324\n",
            "Epoch 345/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0720 - accuracy: 0.9831 - val_loss: 0.4527 - val_accuracy: 0.9324\n",
            "Epoch 346/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0641 - accuracy: 0.9780 - val_loss: 0.4383 - val_accuracy: 0.9392\n",
            "Epoch 347/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0685 - accuracy: 0.9831 - val_loss: 0.4257 - val_accuracy: 0.9459\n",
            "Epoch 348/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0644 - accuracy: 0.9780 - val_loss: 0.5094 - val_accuracy: 0.9257\n",
            "Epoch 349/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0713 - accuracy: 0.9729 - val_loss: 0.5270 - val_accuracy: 0.9257\n",
            "Epoch 350/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0532 - accuracy: 0.9865 - val_loss: 0.4789 - val_accuracy: 0.9324\n",
            "Epoch 351/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0668 - accuracy: 0.9865 - val_loss: 0.4790 - val_accuracy: 0.9392\n",
            "Epoch 352/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0702 - accuracy: 0.9831 - val_loss: 0.5213 - val_accuracy: 0.9324\n",
            "Epoch 353/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0572 - accuracy: 0.9797 - val_loss: 0.5341 - val_accuracy: 0.9324\n",
            "Epoch 354/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0508 - accuracy: 0.9865 - val_loss: 0.4607 - val_accuracy: 0.9392\n",
            "Epoch 355/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0532 - accuracy: 0.9848 - val_loss: 0.4419 - val_accuracy: 0.9392\n",
            "Epoch 356/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0705 - accuracy: 0.9763 - val_loss: 0.4447 - val_accuracy: 0.9459\n",
            "Epoch 357/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0554 - accuracy: 0.9814 - val_loss: 0.4530 - val_accuracy: 0.9324\n",
            "Epoch 358/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0624 - accuracy: 0.9729 - val_loss: 0.4810 - val_accuracy: 0.9324\n",
            "Epoch 359/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0529 - accuracy: 0.9848 - val_loss: 0.5030 - val_accuracy: 0.9324\n",
            "Epoch 360/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0597 - accuracy: 0.9831 - val_loss: 0.4661 - val_accuracy: 0.9392\n",
            "Epoch 361/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0438 - accuracy: 0.9882 - val_loss: 0.4661 - val_accuracy: 0.9392\n",
            "Epoch 362/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 0.4871 - val_accuracy: 0.9459\n",
            "Epoch 363/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.4783 - val_accuracy: 0.9392\n",
            "Epoch 364/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 0.4709 - val_accuracy: 0.9392\n",
            "Epoch 365/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 0.4962 - val_accuracy: 0.9392\n",
            "Epoch 366/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.5070 - val_accuracy: 0.9392\n",
            "Epoch 367/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0528 - accuracy: 0.9865 - val_loss: 0.5130 - val_accuracy: 0.9324\n",
            "Epoch 368/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0434 - accuracy: 0.9882 - val_loss: 0.5059 - val_accuracy: 0.9459\n",
            "Epoch 369/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0677 - accuracy: 0.9831 - val_loss: 0.4954 - val_accuracy: 0.9392\n",
            "Epoch 370/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0579 - accuracy: 0.9898 - val_loss: 0.4760 - val_accuracy: 0.9459\n",
            "Epoch 371/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0509 - accuracy: 0.9882 - val_loss: 0.5197 - val_accuracy: 0.9392\n",
            "Epoch 372/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0653 - accuracy: 0.9763 - val_loss: 0.5070 - val_accuracy: 0.9392\n",
            "Epoch 373/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0585 - accuracy: 0.9814 - val_loss: 0.4725 - val_accuracy: 0.9459\n",
            "Epoch 374/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.4950 - val_accuracy: 0.9459\n",
            "Epoch 375/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0391 - accuracy: 0.9898 - val_loss: 0.5177 - val_accuracy: 0.9459\n",
            "Epoch 376/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0412 - accuracy: 0.9915 - val_loss: 0.5133 - val_accuracy: 0.9459\n",
            "Epoch 377/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0559 - accuracy: 0.9797 - val_loss: 0.4783 - val_accuracy: 0.9392\n",
            "Epoch 378/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0422 - accuracy: 0.9949 - val_loss: 0.4777 - val_accuracy: 0.9459\n",
            "Epoch 379/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0505 - accuracy: 0.9865 - val_loss: 0.5201 - val_accuracy: 0.9392\n",
            "Epoch 380/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.5427 - val_accuracy: 0.9459\n",
            "Epoch 381/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.5255 - val_accuracy: 0.9392\n",
            "Epoch 382/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0491 - accuracy: 0.9865 - val_loss: 0.5284 - val_accuracy: 0.9459\n",
            "Epoch 383/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0507 - accuracy: 0.9780 - val_loss: 0.5218 - val_accuracy: 0.9459\n",
            "Epoch 384/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.5046 - val_accuracy: 0.9459\n",
            "Epoch 385/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0474 - accuracy: 0.9848 - val_loss: 0.5045 - val_accuracy: 0.9392\n",
            "Epoch 386/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0530 - accuracy: 0.9848 - val_loss: 0.5221 - val_accuracy: 0.9392\n",
            "Epoch 387/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0497 - accuracy: 0.9814 - val_loss: 0.5319 - val_accuracy: 0.9392\n",
            "Epoch 388/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0421 - accuracy: 0.9898 - val_loss: 0.5323 - val_accuracy: 0.9392\n",
            "Epoch 389/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 0.5444 - val_accuracy: 0.9459\n",
            "Epoch 390/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 0.5680 - val_accuracy: 0.9527\n",
            "Epoch 391/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.5853 - val_accuracy: 0.9459\n",
            "Epoch 392/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.5805 - val_accuracy: 0.9392\n",
            "Epoch 393/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 0.5471 - val_accuracy: 0.9527\n",
            "Epoch 394/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.5471 - val_accuracy: 0.9392\n",
            "Epoch 395/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.5183 - val_accuracy: 0.9459\n",
            "Epoch 396/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.5153 - val_accuracy: 0.9459\n",
            "Epoch 397/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0365 - accuracy: 0.9932 - val_loss: 0.5404 - val_accuracy: 0.9392\n",
            "Epoch 398/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.5623 - val_accuracy: 0.9459\n",
            "Epoch 399/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0369 - accuracy: 0.9865 - val_loss: 0.5688 - val_accuracy: 0.9527\n",
            "Epoch 400/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.5293 - val_accuracy: 0.9459\n",
            "Epoch 401/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0452 - accuracy: 0.9814 - val_loss: 0.5320 - val_accuracy: 0.9459\n",
            "Epoch 402/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0392 - accuracy: 0.9848 - val_loss: 0.5438 - val_accuracy: 0.9459\n",
            "Epoch 403/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0598 - accuracy: 0.9848 - val_loss: 0.5319 - val_accuracy: 0.9527\n",
            "Epoch 404/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0497 - accuracy: 0.9882 - val_loss: 0.5651 - val_accuracy: 0.9392\n",
            "Epoch 405/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0447 - accuracy: 0.9915 - val_loss: 0.5338 - val_accuracy: 0.9392\n",
            "Epoch 406/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0425 - accuracy: 0.9932 - val_loss: 0.5188 - val_accuracy: 0.9459\n",
            "Epoch 407/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.5289 - val_accuracy: 0.9459\n",
            "Epoch 408/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.5435 - val_accuracy: 0.9392\n",
            "Epoch 409/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.5470 - val_accuracy: 0.9527\n",
            "Epoch 410/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0488 - accuracy: 0.9780 - val_loss: 0.5593 - val_accuracy: 0.9459\n",
            "Epoch 411/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0519 - accuracy: 0.9882 - val_loss: 0.5436 - val_accuracy: 0.9392\n",
            "Epoch 412/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9932 - val_loss: 0.5423 - val_accuracy: 0.9527\n",
            "Epoch 413/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0393 - accuracy: 0.9898 - val_loss: 0.5585 - val_accuracy: 0.9459\n",
            "Epoch 414/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0308 - accuracy: 0.9949 - val_loss: 0.5949 - val_accuracy: 0.9392\n",
            "Epoch 415/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.6044 - val_accuracy: 0.9459\n",
            "Epoch 416/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0342 - accuracy: 0.9865 - val_loss: 0.5752 - val_accuracy: 0.9459\n",
            "Epoch 417/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.5489 - val_accuracy: 0.9459\n",
            "Epoch 418/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.5366 - val_accuracy: 0.9459\n",
            "Epoch 419/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0426 - accuracy: 0.9898 - val_loss: 0.5363 - val_accuracy: 0.9459\n",
            "Epoch 420/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.5552 - val_accuracy: 0.9392\n",
            "Epoch 421/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0392 - accuracy: 0.9915 - val_loss: 0.5687 - val_accuracy: 0.9527\n",
            "Epoch 422/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.5643 - val_accuracy: 0.9459\n",
            "Epoch 423/2000\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 0.5962 - val_accuracy: 0.9392\n",
            "Epoch 424/2000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.6202 - val_accuracy: 0.9392\n",
            "Epoch 425/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0224 - accuracy: 0.9966 - val_loss: 0.6101 - val_accuracy: 0.9527\n",
            "Epoch 426/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.5868 - val_accuracy: 0.9392\n",
            "Epoch 427/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.5277 - val_accuracy: 0.9459\n",
            "Epoch 428/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.5332 - val_accuracy: 0.9527\n",
            "Epoch 429/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0380 - accuracy: 0.9898 - val_loss: 0.5520 - val_accuracy: 0.9527\n",
            "Epoch 430/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0229 - accuracy: 0.9983 - val_loss: 0.5832 - val_accuracy: 0.9527\n",
            "Epoch 431/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0280 - accuracy: 0.9949 - val_loss: 0.5973 - val_accuracy: 0.9527\n",
            "Epoch 432/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0359 - accuracy: 0.9932 - val_loss: 0.5753 - val_accuracy: 0.9459\n",
            "Epoch 433/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.5995 - val_accuracy: 0.9459\n",
            "Epoch 434/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.6122 - val_accuracy: 0.9459\n",
            "Epoch 435/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.5972 - val_accuracy: 0.9459\n",
            "Epoch 436/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.5448 - val_accuracy: 0.9459\n",
            "Epoch 437/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.5340 - val_accuracy: 0.9459\n",
            "Epoch 438/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.5414 - val_accuracy: 0.9459\n",
            "Epoch 439/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 0.5692 - val_accuracy: 0.9459\n",
            "Epoch 440/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.5679 - val_accuracy: 0.9459\n",
            "Epoch 441/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.5338 - val_accuracy: 0.9459\n",
            "Epoch 442/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.5628 - val_accuracy: 0.9324\n",
            "Epoch 443/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.5926 - val_accuracy: 0.9459\n",
            "Epoch 444/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0391 - accuracy: 0.9848 - val_loss: 0.6035 - val_accuracy: 0.9459\n",
            "Epoch 445/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.5613 - val_accuracy: 0.9459\n",
            "Epoch 446/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0402 - accuracy: 0.9898 - val_loss: 0.5582 - val_accuracy: 0.9459\n",
            "Epoch 447/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0273 - accuracy: 0.9949 - val_loss: 0.5854 - val_accuracy: 0.9459\n",
            "Epoch 448/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.5812 - val_accuracy: 0.9459\n",
            "Epoch 449/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.5801 - val_accuracy: 0.9527\n",
            "Epoch 450/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0384 - accuracy: 0.9848 - val_loss: 0.5950 - val_accuracy: 0.9527\n",
            "Epoch 451/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.6288 - val_accuracy: 0.9459\n",
            "Epoch 452/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0242 - accuracy: 0.9949 - val_loss: 0.6456 - val_accuracy: 0.9459\n",
            "Epoch 453/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.6067 - val_accuracy: 0.9459\n",
            "Epoch 454/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0365 - accuracy: 0.9865 - val_loss: 0.5600 - val_accuracy: 0.9459\n",
            "Epoch 455/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0378 - accuracy: 0.9915 - val_loss: 0.5849 - val_accuracy: 0.9459\n",
            "Epoch 456/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0363 - accuracy: 0.9932 - val_loss: 0.6500 - val_accuracy: 0.9527\n",
            "Epoch 457/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.6244 - val_accuracy: 0.9459\n",
            "Epoch 458/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.6335 - val_accuracy: 0.9459\n",
            "Epoch 459/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.6446 - val_accuracy: 0.9392\n",
            "Epoch 460/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0411 - accuracy: 0.9898 - val_loss: 0.6256 - val_accuracy: 0.9459\n",
            "Epoch 461/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.5975 - val_accuracy: 0.9459\n",
            "Epoch 462/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0440 - accuracy: 0.9882 - val_loss: 0.5895 - val_accuracy: 0.9459\n",
            "Epoch 463/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.5805 - val_accuracy: 0.9392\n",
            "Epoch 464/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0229 - accuracy: 0.9966 - val_loss: 0.5717 - val_accuracy: 0.9459\n",
            "Epoch 465/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 0.5810 - val_accuracy: 0.9459\n",
            "Epoch 466/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0241 - accuracy: 0.9966 - val_loss: 0.6102 - val_accuracy: 0.9459\n",
            "Epoch 467/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 0.5990 - val_accuracy: 0.9459\n",
            "Epoch 468/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.6096 - val_accuracy: 0.9459\n",
            "Epoch 469/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0321 - accuracy: 0.9898 - val_loss: 0.6411 - val_accuracy: 0.9459\n",
            "Epoch 470/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.6660 - val_accuracy: 0.9459\n",
            "Epoch 471/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.6380 - val_accuracy: 0.9459\n",
            "Epoch 472/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.6291 - val_accuracy: 0.9527\n",
            "Epoch 473/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.6270 - val_accuracy: 0.9527\n",
            "Epoch 474/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.6347 - val_accuracy: 0.9459\n",
            "Epoch 475/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0250 - accuracy: 0.9882 - val_loss: 0.6472 - val_accuracy: 0.9459\n",
            "Epoch 476/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0164 - accuracy: 0.9983 - val_loss: 0.6466 - val_accuracy: 0.9459\n",
            "Epoch 477/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 0.6367 - val_accuracy: 0.9527\n",
            "Epoch 478/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.6231 - val_accuracy: 0.9459\n",
            "Epoch 479/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0289 - accuracy: 0.9932 - val_loss: 0.6243 - val_accuracy: 0.9459\n",
            "Epoch 480/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.6335 - val_accuracy: 0.9459\n",
            "Epoch 481/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.6533 - val_accuracy: 0.9459\n",
            "Epoch 482/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 0.6590 - val_accuracy: 0.9459\n",
            "Epoch 483/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.6639 - val_accuracy: 0.9459\n",
            "Epoch 484/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.6723 - val_accuracy: 0.9459\n",
            "Epoch 485/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.6511 - val_accuracy: 0.9459\n",
            "Epoch 486/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0180 - accuracy: 0.9983 - val_loss: 0.6599 - val_accuracy: 0.9459\n",
            "Epoch 487/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.6596 - val_accuracy: 0.9459\n",
            "Epoch 488/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.6478 - val_accuracy: 0.9459\n",
            "Epoch 489/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.6399 - val_accuracy: 0.9459\n",
            "Epoch 490/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0353 - accuracy: 0.9848 - val_loss: 0.6208 - val_accuracy: 0.9459\n",
            "Epoch 491/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0256 - accuracy: 0.9882 - val_loss: 0.6178 - val_accuracy: 0.9527\n",
            "Epoch 492/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0204 - accuracy: 0.9966 - val_loss: 0.6361 - val_accuracy: 0.9459\n",
            "Epoch 493/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0339 - accuracy: 0.9831 - val_loss: 0.6706 - val_accuracy: 0.9459\n",
            "Epoch 494/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.6756 - val_accuracy: 0.9527\n",
            "Epoch 495/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.6656 - val_accuracy: 0.9459\n",
            "Epoch 496/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.6530 - val_accuracy: 0.9459\n",
            "Epoch 497/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.6351 - val_accuracy: 0.9459\n",
            "Epoch 498/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0303 - accuracy: 0.9949 - val_loss: 0.6361 - val_accuracy: 0.9459\n",
            "Epoch 499/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0178 - accuracy: 0.9983 - val_loss: 0.6614 - val_accuracy: 0.9459\n",
            "Epoch 500/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0285 - accuracy: 0.9898 - val_loss: 0.6830 - val_accuracy: 0.9459\n",
            "Epoch 501/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.6785 - val_accuracy: 0.9459\n",
            "Epoch 502/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0174 - accuracy: 0.9983 - val_loss: 0.6702 - val_accuracy: 0.9459\n",
            "Epoch 503/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0153 - accuracy: 0.9983 - val_loss: 0.6818 - val_accuracy: 0.9459\n",
            "Epoch 504/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.6812 - val_accuracy: 0.9459\n",
            "Epoch 505/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.6868 - val_accuracy: 0.9459\n",
            "Epoch 506/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0267 - accuracy: 0.9865 - val_loss: 0.6552 - val_accuracy: 0.9459\n",
            "Epoch 507/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.6207 - val_accuracy: 0.9392\n",
            "Epoch 508/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0220 - accuracy: 0.9966 - val_loss: 0.6255 - val_accuracy: 0.9459\n",
            "Epoch 509/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.6533 - val_accuracy: 0.9527\n",
            "Epoch 510/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 0.6461 - val_accuracy: 0.9459\n",
            "Epoch 511/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0145 - accuracy: 0.9983 - val_loss: 0.6606 - val_accuracy: 0.9392\n",
            "Epoch 512/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0696 - accuracy: 0.9865 - val_loss: 0.6175 - val_accuracy: 0.9459\n",
            "Epoch 513/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0256 - accuracy: 0.9949 - val_loss: 0.6219 - val_accuracy: 0.9527\n",
            "Epoch 514/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.6314 - val_accuracy: 0.9459\n",
            "Epoch 515/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.6551 - val_accuracy: 0.9459\n",
            "Epoch 516/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.6801 - val_accuracy: 0.9459\n",
            "Epoch 517/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.9459\n",
            "Epoch 518/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.7192 - val_accuracy: 0.9459\n",
            "Epoch 519/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0199 - accuracy: 0.9898 - val_loss: 0.7169 - val_accuracy: 0.9459\n",
            "Epoch 520/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0206 - accuracy: 0.9983 - val_loss: 0.6928 - val_accuracy: 0.9459\n",
            "Epoch 521/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.6863 - val_accuracy: 0.9459\n",
            "Epoch 522/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.6659 - val_accuracy: 0.9459\n",
            "Epoch 523/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.6548 - val_accuracy: 0.9459\n",
            "Epoch 524/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.6647 - val_accuracy: 0.9459\n",
            "Epoch 525/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.6793 - val_accuracy: 0.9459\n",
            "Epoch 526/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.7038 - val_accuracy: 0.9459\n",
            "Epoch 527/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.7171 - val_accuracy: 0.9527\n",
            "Epoch 528/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0224 - accuracy: 0.9966 - val_loss: 0.7120 - val_accuracy: 0.9527\n",
            "Epoch 529/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.6916 - val_accuracy: 0.9459\n",
            "Epoch 530/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.9459\n",
            "Epoch 531/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 0.6763 - val_accuracy: 0.9459\n",
            "Epoch 532/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.6771 - val_accuracy: 0.9459\n",
            "Epoch 533/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0195 - accuracy: 0.9966 - val_loss: 0.6881 - val_accuracy: 0.9459\n",
            "Epoch 534/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.6954 - val_accuracy: 0.9459\n",
            "Epoch 535/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.6972 - val_accuracy: 0.9459\n",
            "Epoch 536/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.7136 - val_accuracy: 0.9459\n",
            "Epoch 537/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.7187 - val_accuracy: 0.9459\n",
            "Epoch 538/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.7094 - val_accuracy: 0.9459\n",
            "Epoch 539/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.7053 - val_accuracy: 0.9459\n",
            "Epoch 540/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 0.7076 - val_accuracy: 0.9459\n",
            "Epoch 541/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.7082 - val_accuracy: 0.9459\n",
            "Epoch 542/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.7136 - val_accuracy: 0.9459\n",
            "Epoch 543/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.7126 - val_accuracy: 0.9459\n",
            "Epoch 544/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.7035 - val_accuracy: 0.9459\n",
            "Epoch 545/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.6973 - val_accuracy: 0.9459\n",
            "Epoch 546/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.7058 - val_accuracy: 0.9459\n",
            "Epoch 547/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.7054 - val_accuracy: 0.9459\n",
            "Epoch 548/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.7155 - val_accuracy: 0.9459\n",
            "Epoch 549/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0214 - accuracy: 0.9966 - val_loss: 0.6706 - val_accuracy: 0.9459\n",
            "Epoch 550/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.6778 - val_accuracy: 0.9459\n",
            "Epoch 551/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.7008 - val_accuracy: 0.9459\n",
            "Epoch 552/2000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.7039 - val_accuracy: 0.9459\n",
            "Epoch 553/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.7016 - val_accuracy: 0.9459\n",
            "Epoch 554/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.7018 - val_accuracy: 0.9459\n",
            "Epoch 555/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.7031 - val_accuracy: 0.9459\n",
            "Epoch 556/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.7022 - val_accuracy: 0.9459\n",
            "Epoch 557/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.6871 - val_accuracy: 0.9459\n",
            "Epoch 558/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.6830 - val_accuracy: 0.9459\n",
            "Epoch 559/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.7027 - val_accuracy: 0.9459\n",
            "Epoch 560/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.6871 - val_accuracy: 0.9459\n",
            "Epoch 561/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.6933 - val_accuracy: 0.9459\n",
            "Epoch 562/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.7025 - val_accuracy: 0.9459\n",
            "Epoch 563/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.6993 - val_accuracy: 0.9459\n",
            "Epoch 564/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.6935 - val_accuracy: 0.9459\n",
            "Epoch 565/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.9459\n",
            "Epoch 566/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.7162 - val_accuracy: 0.9459\n",
            "Epoch 567/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.7244 - val_accuracy: 0.9459\n",
            "Epoch 568/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.7466 - val_accuracy: 0.9459\n",
            "Epoch 569/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.7350 - val_accuracy: 0.9459\n",
            "Epoch 570/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.7297 - val_accuracy: 0.9459\n",
            "Epoch 571/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7407 - val_accuracy: 0.9459\n",
            "Epoch 572/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.9459\n",
            "Epoch 573/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0135 - accuracy: 0.9932 - val_loss: 0.7460 - val_accuracy: 0.9459\n",
            "Epoch 574/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.7320 - val_accuracy: 0.9459\n",
            "Epoch 575/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.7173 - val_accuracy: 0.9459\n",
            "Epoch 576/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.7159 - val_accuracy: 0.9459\n",
            "Epoch 577/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.6986 - val_accuracy: 0.9459\n",
            "Epoch 578/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.7049 - val_accuracy: 0.9459\n",
            "Epoch 579/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.7213 - val_accuracy: 0.9459\n",
            "Epoch 580/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.7237 - val_accuracy: 0.9459\n",
            "Epoch 581/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.7320 - val_accuracy: 0.9459\n",
            "Epoch 582/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.7394 - val_accuracy: 0.9459\n",
            "Epoch 583/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.7296 - val_accuracy: 0.9459\n",
            "Epoch 584/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.7152 - val_accuracy: 0.9459\n",
            "Epoch 585/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.7149 - val_accuracy: 0.9527\n",
            "Epoch 586/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0241 - accuracy: 0.9882 - val_loss: 0.6945 - val_accuracy: 0.9527\n",
            "Epoch 587/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0211 - accuracy: 0.9915 - val_loss: 0.6975 - val_accuracy: 0.9459\n",
            "Epoch 588/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0137 - accuracy: 0.9983 - val_loss: 0.7290 - val_accuracy: 0.9459\n",
            "Epoch 589/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.7418 - val_accuracy: 0.9459\n",
            "Epoch 590/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.7408 - val_accuracy: 0.9459\n",
            "Epoch 591/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0340 - accuracy: 0.9932 - val_loss: 0.7240 - val_accuracy: 0.9459\n",
            "Epoch 592/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0239 - accuracy: 0.9898 - val_loss: 0.6844 - val_accuracy: 0.9459\n",
            "Epoch 593/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0308 - accuracy: 0.9932 - val_loss: 0.6749 - val_accuracy: 0.9459\n",
            "Epoch 594/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.7009 - val_accuracy: 0.9459\n",
            "Epoch 595/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.7426 - val_accuracy: 0.9459\n",
            "Epoch 596/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.7778 - val_accuracy: 0.9459\n",
            "Epoch 597/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.7730 - val_accuracy: 0.9459\n",
            "Epoch 598/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.7393 - val_accuracy: 0.9459\n",
            "Epoch 599/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0162 - accuracy: 0.9983 - val_loss: 0.7213 - val_accuracy: 0.9459\n",
            "Epoch 600/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0220 - accuracy: 0.9898 - val_loss: 0.7294 - val_accuracy: 0.9459\n",
            "Epoch 601/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.7433 - val_accuracy: 0.9459\n",
            "Epoch 602/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.7539 - val_accuracy: 0.9459\n",
            "Epoch 603/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.9459\n",
            "Epoch 604/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.7906 - val_accuracy: 0.9459\n",
            "Epoch 605/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0143 - accuracy: 0.9932 - val_loss: 0.8193 - val_accuracy: 0.9459\n",
            "Epoch 606/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.8278 - val_accuracy: 0.9459\n",
            "Epoch 607/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0214 - accuracy: 0.9915 - val_loss: 0.7991 - val_accuracy: 0.9459\n",
            "Epoch 608/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.7643 - val_accuracy: 0.9459\n",
            "Epoch 609/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.7789 - val_accuracy: 0.9459\n",
            "Epoch 610/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.8046 - val_accuracy: 0.9459\n",
            "Epoch 611/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0251 - accuracy: 0.9882 - val_loss: 0.7821 - val_accuracy: 0.9459\n",
            "Epoch 612/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.7913 - val_accuracy: 0.9459\n",
            "Epoch 613/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.7953 - val_accuracy: 0.9459\n",
            "Epoch 614/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.8054 - val_accuracy: 0.9459\n",
            "Epoch 615/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.7974 - val_accuracy: 0.9459\n",
            "Epoch 616/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.9459\n",
            "Epoch 617/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.8036 - val_accuracy: 0.9459\n",
            "Epoch 618/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.8082 - val_accuracy: 0.9459\n",
            "Epoch 619/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.9459\n",
            "Epoch 620/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8113 - val_accuracy: 0.9459\n",
            "Epoch 621/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.8154 - val_accuracy: 0.9459\n",
            "Epoch 622/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.8035 - val_accuracy: 0.9459\n",
            "Epoch 623/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.9459\n",
            "Epoch 624/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.8157 - val_accuracy: 0.9459\n",
            "Epoch 625/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.8173 - val_accuracy: 0.9459\n",
            "Epoch 626/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.8138 - val_accuracy: 0.9459\n",
            "Epoch 627/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.9459\n",
            "Epoch 628/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.8003 - val_accuracy: 0.9459\n",
            "Epoch 629/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.8187 - val_accuracy: 0.9459\n",
            "Epoch 630/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.8239 - val_accuracy: 0.9459\n",
            "Epoch 631/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.8304 - val_accuracy: 0.9459\n",
            "Epoch 632/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.8299 - val_accuracy: 0.9459\n",
            "Epoch 633/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.8218 - val_accuracy: 0.9459\n",
            "Epoch 634/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.7968 - val_accuracy: 0.9459\n",
            "Epoch 635/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.7816 - val_accuracy: 0.9459\n",
            "Epoch 636/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.7507 - val_accuracy: 0.9459\n",
            "Epoch 637/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.7334 - val_accuracy: 0.9459\n",
            "Epoch 638/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0226 - accuracy: 0.9966 - val_loss: 0.7357 - val_accuracy: 0.9459\n",
            "Epoch 639/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.9459\n",
            "Epoch 640/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.7955 - val_accuracy: 0.9527\n",
            "Epoch 641/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.8300 - val_accuracy: 0.9527\n",
            "Epoch 642/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0160 - accuracy: 0.9915 - val_loss: 0.8315 - val_accuracy: 0.9459\n",
            "Epoch 643/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.8387 - val_accuracy: 0.9459\n",
            "Epoch 644/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.8381 - val_accuracy: 0.9459\n",
            "Epoch 645/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.9459\n",
            "Epoch 646/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.8393 - val_accuracy: 0.9459\n",
            "Epoch 647/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.8337 - val_accuracy: 0.9459\n",
            "Epoch 648/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.8298 - val_accuracy: 0.9459\n",
            "Epoch 649/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.8289 - val_accuracy: 0.9459\n",
            "Epoch 650/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.8359 - val_accuracy: 0.9459\n",
            "Epoch 651/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.8492 - val_accuracy: 0.9459\n",
            "Epoch 652/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.8617 - val_accuracy: 0.9459\n",
            "Epoch 653/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.9459\n",
            "Epoch 654/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0124 - accuracy: 0.9932 - val_loss: 0.8790 - val_accuracy: 0.9459\n",
            "Epoch 655/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.8699 - val_accuracy: 0.9459\n",
            "Epoch 656/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.8483 - val_accuracy: 0.9459\n",
            "Epoch 657/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.8412 - val_accuracy: 0.9459\n",
            "Epoch 658/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8482 - val_accuracy: 0.9527\n",
            "Epoch 659/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.8593 - val_accuracy: 0.9459\n",
            "Epoch 660/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.8687 - val_accuracy: 0.9459\n",
            "Epoch 661/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.8767 - val_accuracy: 0.9459\n",
            "Epoch 662/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.9459\n",
            "Epoch 663/2000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.0182 - accuracy: 0.9966 - val_loss: 0.8682 - val_accuracy: 0.9459\n",
            "Epoch 664/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.9459\n",
            "Epoch 665/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.9459\n",
            "Epoch 666/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.9459\n",
            "Epoch 667/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.9007 - val_accuracy: 0.9459\n",
            "Epoch 668/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.9037 - val_accuracy: 0.9459\n",
            "Epoch 669/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.8939 - val_accuracy: 0.9459\n",
            "Epoch 670/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.8949 - val_accuracy: 0.9459\n",
            "Epoch 671/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.8885 - val_accuracy: 0.9459\n",
            "Epoch 672/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.9459\n",
            "Epoch 673/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.9459\n",
            "Epoch 674/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.9459\n",
            "Epoch 675/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.9459\n",
            "Epoch 676/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.9459\n",
            "Epoch 677/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.8655 - val_accuracy: 0.9459\n",
            "Epoch 678/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.9459\n",
            "Epoch 679/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.9459\n",
            "Epoch 680/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0089 - accuracy: 0.9949 - val_loss: 0.8928 - val_accuracy: 0.9459\n",
            "Epoch 681/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.9459\n",
            "Epoch 682/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.9459\n",
            "Epoch 683/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.9459\n",
            "Epoch 684/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0129 - accuracy: 0.9932 - val_loss: 0.8893 - val_accuracy: 0.9459\n",
            "Epoch 685/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8917 - val_accuracy: 0.9459\n",
            "Epoch 686/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.9007 - val_accuracy: 0.9459\n",
            "Epoch 687/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.9459\n",
            "Epoch 688/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.8703 - val_accuracy: 0.9459\n",
            "Epoch 689/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.8477 - val_accuracy: 0.9459\n",
            "Epoch 690/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.8337 - val_accuracy: 0.9459\n",
            "Epoch 691/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 0.8288 - val_accuracy: 0.9527\n",
            "Epoch 692/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.8290 - val_accuracy: 0.9527\n",
            "Epoch 693/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.8369 - val_accuracy: 0.9459\n",
            "Epoch 694/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8512 - val_accuracy: 0.9459\n",
            "Epoch 695/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.8634 - val_accuracy: 0.9459\n",
            "Epoch 696/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.8859 - val_accuracy: 0.9459\n",
            "Epoch 697/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.9030 - val_accuracy: 0.9459\n",
            "Epoch 698/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 0.9147 - val_accuracy: 0.9459\n",
            "Epoch 699/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.9145 - val_accuracy: 0.9459\n",
            "Epoch 700/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.9459\n",
            "Epoch 701/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0124 - accuracy: 0.9932 - val_loss: 0.8995 - val_accuracy: 0.9459\n",
            "Epoch 702/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.8967 - val_accuracy: 0.9459\n",
            "Epoch 703/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.9459\n",
            "Epoch 704/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.8838 - val_accuracy: 0.9459\n",
            "Epoch 705/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.9459\n",
            "Epoch 706/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.8833 - val_accuracy: 0.9459\n",
            "Epoch 707/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.9017 - val_accuracy: 0.9459\n",
            "Epoch 708/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.9527\n",
            "Epoch 709/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.9051 - val_accuracy: 0.9459\n",
            "Epoch 710/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.8770 - val_accuracy: 0.9459\n",
            "Epoch 711/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8648 - val_accuracy: 0.9459\n",
            "Epoch 712/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.9459\n",
            "Epoch 713/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.8637 - val_accuracy: 0.9459\n",
            "Epoch 714/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 0.9459\n",
            "Epoch 715/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.8762 - val_accuracy: 0.9459\n",
            "Epoch 716/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0080 - accuracy: 0.9949 - val_loss: 0.8775 - val_accuracy: 0.9459\n",
            "Epoch 717/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8889 - val_accuracy: 0.9459\n",
            "Epoch 718/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.9059 - val_accuracy: 0.9459\n",
            "Epoch 719/2000\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.9459\n",
            "Epoch 720/2000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.9203 - val_accuracy: 0.9459\n",
            "Epoch 721/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.9167 - val_accuracy: 0.9459\n",
            "Epoch 722/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.8903 - val_accuracy: 0.9459\n",
            "Epoch 723/2000\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.8690 - val_accuracy: 0.9459\n",
            "Epoch 724/2000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.8550 - val_accuracy: 0.9459\n",
            "Epoch 725/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.8545 - val_accuracy: 0.9459\n",
            "Epoch 726/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.8494 - val_accuracy: 0.9459\n",
            "Epoch 727/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.9459\n",
            "Epoch 728/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.8534 - val_accuracy: 0.9459\n",
            "Epoch 729/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8635 - val_accuracy: 0.9459\n",
            "Epoch 730/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.9459\n",
            "Epoch 731/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.9459\n",
            "Epoch 732/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 0.8901 - val_accuracy: 0.9459\n",
            "Epoch 733/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.9459\n",
            "Epoch 734/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.9459\n",
            "Epoch 735/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.9459\n",
            "Epoch 736/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9184 - val_accuracy: 0.9459\n",
            "Epoch 737/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.9459\n",
            "Epoch 738/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9247 - val_accuracy: 0.9459\n",
            "Epoch 739/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.9178 - val_accuracy: 0.9459\n",
            "Epoch 740/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.9459\n",
            "Epoch 741/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.9107 - val_accuracy: 0.9459\n",
            "Epoch 742/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.8994 - val_accuracy: 0.9459\n",
            "Epoch 743/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.9459\n",
            "Epoch 744/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.9459\n",
            "Epoch 745/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.9062 - val_accuracy: 0.9459\n",
            "Epoch 746/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.9087 - val_accuracy: 0.9459\n",
            "Epoch 747/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 0.8996 - val_accuracy: 0.9459\n",
            "Epoch 748/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.9459\n",
            "Epoch 749/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.8946 - val_accuracy: 0.9459\n",
            "Epoch 750/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.8984 - val_accuracy: 0.9459\n",
            "Epoch 751/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.9459\n",
            "Epoch 752/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9092 - val_accuracy: 0.9459\n",
            "Epoch 753/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.8703 - val_accuracy: 0.9459\n",
            "Epoch 754/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.8651 - val_accuracy: 0.9527\n",
            "Epoch 755/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.8546 - val_accuracy: 0.9459\n",
            "Epoch 756/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.8474 - val_accuracy: 0.9459\n",
            "Epoch 757/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.9459\n",
            "Epoch 758/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8625 - val_accuracy: 0.9459\n",
            "Epoch 759/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.9459\n",
            "Epoch 760/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.8726 - val_accuracy: 0.9459\n",
            "Epoch 761/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.9459\n",
            "Epoch 762/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.8682 - val_accuracy: 0.9459\n",
            "Epoch 763/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.8714 - val_accuracy: 0.9459\n",
            "Epoch 764/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.9459\n",
            "Epoch 765/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.8536 - val_accuracy: 0.9459\n",
            "Epoch 766/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.9459\n",
            "Epoch 767/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.8626 - val_accuracy: 0.9459\n",
            "Epoch 768/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.8705 - val_accuracy: 0.9459\n",
            "Epoch 769/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.8882 - val_accuracy: 0.9459\n",
            "Epoch 770/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.9459\n",
            "Epoch 771/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.9167 - val_accuracy: 0.9459\n",
            "Epoch 772/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.9082 - val_accuracy: 0.9459\n",
            "Epoch 773/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9119 - val_accuracy: 0.9459\n",
            "Epoch 774/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.9151 - val_accuracy: 0.9459\n",
            "Epoch 775/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.9459\n",
            "Epoch 776/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9459\n",
            "Epoch 777/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.9288 - val_accuracy: 0.9459\n",
            "Epoch 778/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.9459\n",
            "Epoch 779/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.9459\n",
            "Epoch 780/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.9459\n",
            "Epoch 781/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.9459\n",
            "Epoch 782/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.9257 - val_accuracy: 0.9459\n",
            "Epoch 783/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.9459\n",
            "Epoch 784/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.9459\n",
            "Epoch 785/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.9459\n",
            "Epoch 786/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.9459\n",
            "Epoch 787/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.9443 - val_accuracy: 0.9459\n",
            "Epoch 788/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.9459\n",
            "Epoch 789/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.9459\n",
            "Epoch 790/2000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.9343 - val_accuracy: 0.9459\n",
            "Epoch 791/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.9326 - val_accuracy: 0.9459\n",
            "Epoch 792/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.9086 - val_accuracy: 0.9459\n",
            "Epoch 793/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.9459\n",
            "Epoch 794/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.9459\n",
            "Epoch 795/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.9030 - val_accuracy: 0.9459\n",
            "Epoch 796/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.8832 - val_accuracy: 0.9459\n",
            "Epoch 797/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9459\n",
            "Epoch 798/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.8736 - val_accuracy: 0.9459\n",
            "Epoch 799/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.9459\n",
            "Epoch 800/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.9459\n",
            "Epoch 801/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.9459\n",
            "Epoch 802/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.9459\n",
            "Epoch 803/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0048 - accuracy: 0.9966 - val_loss: 0.8979 - val_accuracy: 0.9459\n",
            "Epoch 804/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.8862 - val_accuracy: 0.9459\n",
            "Epoch 805/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.9459\n",
            "Epoch 806/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.9459\n",
            "Epoch 807/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.9459\n",
            "Epoch 808/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8948 - val_accuracy: 0.9459\n",
            "Epoch 809/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.8997 - val_accuracy: 0.9459\n",
            "Epoch 810/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.8976 - val_accuracy: 0.9459\n",
            "Epoch 811/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.8883 - val_accuracy: 0.9459\n",
            "Epoch 812/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8856 - val_accuracy: 0.9459\n",
            "Epoch 813/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8901 - val_accuracy: 0.9459\n",
            "Epoch 814/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.8955 - val_accuracy: 0.9459\n",
            "Epoch 815/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.9090 - val_accuracy: 0.9459\n",
            "Epoch 816/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.9459\n",
            "Epoch 817/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.9459\n",
            "Epoch 818/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.9459\n",
            "Epoch 819/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9431 - val_accuracy: 0.9459\n",
            "Epoch 820/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.9475 - val_accuracy: 0.9459\n",
            "Epoch 821/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.9459\n",
            "Epoch 822/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.9472 - val_accuracy: 0.9459\n",
            "Epoch 823/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.9383 - val_accuracy: 0.9459\n",
            "Epoch 824/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.9260 - val_accuracy: 0.9459\n",
            "Epoch 825/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.9089 - val_accuracy: 0.9459\n",
            "Epoch 826/2000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.9014 - val_accuracy: 0.9459\n",
            "Epoch 827/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.9459\n",
            "Epoch 828/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.9459\n",
            "Epoch 829/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9091 - val_accuracy: 0.9459\n",
            "Epoch 830/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.9214 - val_accuracy: 0.9459\n",
            "Epoch 831/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.9459\n",
            "Epoch 832/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.9459\n",
            "Epoch 833/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.9459\n",
            "Epoch 834/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.9459\n",
            "Epoch 835/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.9459\n",
            "Epoch 836/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.9459\n",
            "Epoch 837/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.9459\n",
            "Epoch 838/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.9459\n",
            "Epoch 839/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.9459\n",
            "Epoch 840/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.9459\n",
            "Epoch 841/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.9428 - val_accuracy: 0.9459\n",
            "Epoch 842/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.9450 - val_accuracy: 0.9459\n",
            "Epoch 843/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.9459\n",
            "Epoch 844/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.9459\n",
            "Epoch 845/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.9459\n",
            "Epoch 846/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.9459\n",
            "Epoch 847/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.9495 - val_accuracy: 0.9459\n",
            "Epoch 848/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.9459\n",
            "Epoch 849/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9459\n",
            "Epoch 850/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.9242 - val_accuracy: 0.9459\n",
            "Epoch 851/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.9459\n",
            "Epoch 852/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.9459\n",
            "Epoch 853/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.9459\n",
            "Epoch 854/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.9459\n",
            "Epoch 855/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.9459\n",
            "Epoch 856/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9459\n",
            "Epoch 857/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.9459\n",
            "Epoch 858/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.9478 - val_accuracy: 0.9459\n",
            "Epoch 859/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0062 - accuracy: 0.9966 - val_loss: 0.9418 - val_accuracy: 0.9459\n",
            "Epoch 860/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.9459\n",
            "Epoch 861/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.9459\n",
            "Epoch 862/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.9459\n",
            "Epoch 863/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.9459\n",
            "Epoch 864/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.9459\n",
            "Epoch 865/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.9459\n",
            "Epoch 866/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 8.7870e-04 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.9459\n",
            "Epoch 867/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.9459\n",
            "Epoch 868/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.9459\n",
            "Epoch 869/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.9459\n",
            "Epoch 870/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.9435 - val_accuracy: 0.9459\n",
            "Epoch 871/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9247 - val_accuracy: 0.9459\n",
            "Epoch 872/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.9028 - val_accuracy: 0.9459\n",
            "Epoch 873/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.9459\n",
            "Epoch 874/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.9459\n",
            "Epoch 875/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.9459\n",
            "Epoch 876/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.9459\n",
            "Epoch 877/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9331 - val_accuracy: 0.9459\n",
            "Epoch 878/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9329 - val_accuracy: 0.9459\n",
            "Epoch 879/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9382 - val_accuracy: 0.9527\n",
            "Epoch 880/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.9391 - val_accuracy: 0.9527\n",
            "Epoch 881/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.9527\n",
            "Epoch 882/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.9527\n",
            "Epoch 883/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9490 - val_accuracy: 0.9527\n",
            "Epoch 884/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 0.9544 - val_accuracy: 0.9527\n",
            "Epoch 885/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.9527\n",
            "Epoch 886/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.9527\n",
            "Epoch 887/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.9527\n",
            "Epoch 888/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 9.3406e-04 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.9527\n",
            "Epoch 889/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.9740 - val_accuracy: 0.9527\n",
            "Epoch 890/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9779 - val_accuracy: 0.9527\n",
            "Epoch 891/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.9459\n",
            "Epoch 892/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0033 - accuracy: 0.9983 - val_loss: 0.9717 - val_accuracy: 0.9459\n",
            "Epoch 893/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.9459\n",
            "Epoch 894/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.9720 - val_accuracy: 0.9459\n",
            "Epoch 895/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.9459\n",
            "Epoch 896/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.9459\n",
            "Epoch 897/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.9643 - val_accuracy: 0.9527\n",
            "Epoch 898/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.9673 - val_accuracy: 0.9527\n",
            "Epoch 899/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.9527\n",
            "Epoch 900/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.9527\n",
            "Epoch 901/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.9730 - val_accuracy: 0.9527\n",
            "Epoch 902/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.9720 - val_accuracy: 0.9527\n",
            "Epoch 903/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.9527\n",
            "Epoch 904/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.9491 - val_accuracy: 0.9459\n",
            "Epoch 905/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.9459\n",
            "Epoch 906/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.9459\n",
            "Epoch 907/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9517 - val_accuracy: 0.9459\n",
            "Epoch 908/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9459\n",
            "Epoch 909/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 7.1844e-04 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.9459\n",
            "Epoch 910/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.9578 - val_accuracy: 0.9459\n",
            "Epoch 911/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.9459\n",
            "Epoch 912/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9459\n",
            "Epoch 913/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.9459\n",
            "Epoch 914/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.9459\n",
            "Epoch 915/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 7.3517e-04 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.9459\n",
            "Epoch 916/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.9459\n",
            "Epoch 917/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.9655 - val_accuracy: 0.9459\n",
            "Epoch 918/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.9527\n",
            "Epoch 919/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9527\n",
            "Epoch 920/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9459\n",
            "Epoch 921/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.9459\n",
            "Epoch 922/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.9459\n",
            "Epoch 923/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.9459\n",
            "Epoch 924/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 8.2850e-04 - accuracy: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.9459\n",
            "Epoch 925/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.9459\n",
            "Epoch 926/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.9459\n",
            "Epoch 927/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.9941 - val_accuracy: 0.9459\n",
            "Epoch 928/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 8.5597e-04 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.9459\n",
            "Epoch 929/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 1.0038 - val_accuracy: 0.9459\n",
            "Epoch 930/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.9527\n",
            "Epoch 931/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.0028 - val_accuracy: 0.9459\n",
            "Epoch 932/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.9527\n",
            "Epoch 933/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.9899 - val_accuracy: 0.9459\n",
            "Epoch 934/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9459\n",
            "Epoch 935/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.9459\n",
            "Epoch 936/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.9650 - val_accuracy: 0.9527\n",
            "Epoch 937/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9527\n",
            "Epoch 938/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.9527\n",
            "Epoch 939/2000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.9597 - val_accuracy: 0.9527\n",
            "Epoch 940/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9527\n",
            "Epoch 941/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 0.9710 - val_accuracy: 0.9527\n",
            "Epoch 942/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0033 - accuracy: 0.9983 - val_loss: 0.9635 - val_accuracy: 0.9527\n",
            "Epoch 943/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.9527\n",
            "Epoch 944/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.9527\n",
            "Epoch 945/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 8.3810e-04 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9527\n",
            "Epoch 946/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 0.9869 - val_accuracy: 0.9527\n",
            "Epoch 947/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0023 - accuracy: 0.9983 - val_loss: 0.9926 - val_accuracy: 0.9459\n",
            "Epoch 948/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9972 - val_accuracy: 0.9459\n",
            "Epoch 949/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9977 - val_accuracy: 0.9459\n",
            "Epoch 950/2000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.9459\n",
            "Epoch 951/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.9459\n",
            "Epoch 952/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.9459\n",
            "Epoch 953/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9459\n",
            "Epoch 954/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 9.6352e-04 - accuracy: 1.0000 - val_loss: 0.9830 - val_accuracy: 0.9459\n",
            "Epoch 955/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 0.9459\n",
            "Epoch 956/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.9459\n",
            "Epoch 957/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 8.8171e-04 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.9527\n",
            "Epoch 958/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.9527\n",
            "Epoch 959/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.9527\n",
            "Epoch 960/2000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 7.9521e-04 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.9527\n",
            "Epoch 961/2000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.8812e-04 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.9527\n",
            "Epoch 962/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.9527\n",
            "Epoch 963/2000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.9527\n",
            "Epoch 964/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.9527\n",
            "Epoch 965/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 9.8051e-04 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9527\n",
            "Epoch 966/2000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 7.2429e-04 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.9527\n",
            "Epoch 967/2000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.9527\n",
            "Epoch 968/2000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 1.0161 - val_accuracy: 0.9527\n",
            "Epoch 969/2000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0186 - val_accuracy: 0.9527\n"
          ]
        }
      ],
      "source": [
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=700, restore_best_weights=True)]\n",
        "\n",
        "history=model.fit(\n",
        "    [x_train1,x_train],\n",
        "    y_train1,\n",
        "    validation_data=([x_test1, x_test], y_test1),\n",
        "    epochs=2000,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42doJdzh7mKo",
        "outputId": "8052cec3-964a-472b-fddb-1ddd87fdaa49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8986486486486487\n",
            "f1_score 0.9006622516556292\n",
            "jaccard_score 0.8192771084337349\n",
            "roc_auc_score 0.9013942395890663\n",
            "precision_score 0.9444444444444444\n",
            "recall_score 0.8607594936708861\n"
          ]
        }
      ],
      "source": [
        "#testing prediction\n",
        "\n",
        "#testing prediction\n",
        "ypred1=model.predict([x_test1, x_test])\n",
        "\n",
        "ypred=[]\n",
        "#testing prediction\n",
        "for i in ypred1:\n",
        "    if i[0]>i[1]:\n",
        "        ypred.append(0)\n",
        "    else:\n",
        "        ypred.append(1)\n",
        "from sklearn.metrics import accuracy_score, f1_score,  jaccard_score, roc_auc_score, precision_score, recall_score\n",
        "print(accuracy_score(ypred, y_test1))\n",
        "\n",
        "\n",
        "\n",
        "print('f1_score', f1_score(ypred, y_test1))\n",
        "\n",
        "\n",
        "\n",
        "print('jaccard_score', jaccard_score(ypred, y_test1))\n",
        "print('roc_auc_score', roc_auc_score(ypred, y_test1))\n",
        "print('precision_score', precision_score(ypred, y_test1))\n",
        "\n",
        "print('recall_score', recall_score(ypred, y_test1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([x_test1, x_test], y_test1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO84e1Kbq9vC",
        "outputId": "44ac8c94-f11b-480b-dbf3-a222cca1d075"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.8986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3258945941925049, 0.8986486196517944]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd9Rqyi5DuRJ",
        "outputId": "ec686061-c48f-43db-94fe-fd452ad0b49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9475465313028765\n",
            "f1_score 0.9562764456981665\n",
            "jaccard_score 0.9162162162162162\n",
            "roc_auc_score 0.9507647952905981\n",
            "precision_score 0.9769452449567724\n",
            "recall_score 0.93646408839779\n"
          ]
        }
      ],
      "source": [
        "#training prediction\n",
        "xpred1=model.predict([x_train1, x_train])\n",
        "xpred=[]\n",
        "\n",
        "for i in xpred1:\n",
        "    if i[0]>i[1]:\n",
        "        xpred.append(0)\n",
        "    else:\n",
        "        xpred.append(1)\n",
        "from sklearn.metrics import accuracy_score, f1_score,  jaccard_score, roc_auc_score, precision_score, recall_score\n",
        "print('accuracy', accuracy_score(xpred, y_train1))\n",
        "\n",
        "\n",
        "\n",
        "print('f1_score', f1_score(xpred, y_train1))\n",
        "\n",
        "\n",
        "\n",
        "print('jaccard_score', jaccard_score(xpred, y_train1))\n",
        "print('roc_auc_score', roc_auc_score(xpred, y_train1))\n",
        "print('precision_score', precision_score(xpred, y_train1))\n",
        "\n",
        "print('recall_score', recall_score(xpred, y_train1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "rct_Absenteeism_at_work.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}