{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeaaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reservoirtransformers\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb58cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration import ReservoirTConfig\n",
    "\n",
    "configuration = ReservoirTConfig()\n",
    "\n",
    "configuration.output_size=862\n",
    "configuration.re_output_size=16\n",
    "configuration.max_sequence_length=3399\n",
    "configuration.sequence_length=384\n",
    "configuration.pred_len=96\n",
    "configuration.hidden_size=864\n",
    "configuration.num_attention_heads=4\n",
    "configuration.hidden_dropout_prob=0.0\n",
    "configuration.num_hidden_layers=16\n",
    "configuration.num_reservoirs = 10\n",
    "configuration.intermediate_size=128\n",
    "configuration.reservoir_size = [30, 15, 20, 25, 30, 35, 40, 45, 50, 50]\n",
    "configuration.spectral_radius = [0.6, 0.8, 0.55, 0.6, 0.5, 0.4, 0.3, 0.2, 0.81, 0.05]\n",
    "configuration.sparsity = [0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15]\n",
    "configuration.leaky = [0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39]\n",
    "configuration.attention_probs_dropout_prob=0.0\n",
    "#bert_model = TabularBertForRegression(config=configuration).to(\"cpu\", dtype=float)\n",
    "model = reservoirtransformers.ReservoirTTimeSeries(config=configuration).to(\"cpu\", dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# prepare data for lstm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataset= read_csv('traffic.csv')\n",
    "dataset=dataset.dropna()\n",
    "dataset = dataset.drop(['date'], axis = 1)\n",
    "dataset = dataset.dropna()\n",
    "#data = dataset.values[0:14000]\n",
    "\n",
    "\n",
    "y = dataset.OT.values\n",
    "\n",
    "\n",
    "X = dataset.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = X[0:3000]\n",
    "\n",
    "#X=X[1:]\n",
    "\n",
    "#Reservoir_id = np.array([[0] * len(X[0])] + X[:-1].tolist())\n",
    "# Create a zero column of shape (100, 1)\n",
    "'''\n",
    "zero_col = np.zeros((X.shape[0], 1))\n",
    "\n",
    "# Concatenate the original array with the zero column along the second axis (columns)\n",
    "X = np.hstack((X, zero_col))\n",
    "#X =  dataset.drop(['ate'], axis = 1).values\n",
    "\n",
    "#X_train, X_test, y_train, y_test =train_test_split(X.values, y, test_size=0.2, shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# 1. Preprocess the data into the required format\n",
    "def create_sequences(data, seq_length, pred_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in tqdm(range(len(data) - seq_length - pred_length + 1)):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return torch.tensor(sequences), torch.tensor(targets)\n",
    "\n",
    "X, y = create_sequences(X, seq_length=configuration.sequence_length, pred_length=configuration.pred_len)\n",
    "# Zeros tensor of shape [16941, 384, 1]\n",
    "\n",
    "zeros = torch.zeros((X.size(0), X.size(1), 2), dtype=X.dtype)\n",
    "\n",
    "# Concatenate along the last dimension\n",
    "X = torch.cat((X, zeros), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7955f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch=16\n",
    "indices = np.arange(len(X)) \n",
    "barrier = int(len(indices)/batch)*batch\n",
    "indices = indices[0:barrier]\n",
    "soft_border = int((configuration.sequence_length/batch))+8\n",
    "\n",
    "indices = [indices[i:i+batch] for i in range(0, len(indices), batch)]\n",
    "\n",
    "border1 = int(len(indices)*0.7)\n",
    "border2 = border1+int(len(indices)*0.1)\n",
    "border3 = border2+int(len(indices)*0.2)\n",
    "\n",
    "train_ind = indices[0:border1]\n",
    "val_ind = indices[border1-soft_border: border2]\n",
    "test_ind = indices[border2-soft_border: border3]\n",
    "\n",
    "random.shuffle(train_ind)\n",
    "random.shuffle(val_ind)\n",
    "#random.shuffle(test_ind)\n",
    "\n",
    "\n",
    "X_train = [X[item] for sublist in train_ind for item in sublist]\n",
    "y_train = [y[item] for sublist in train_ind for item in sublist]\n",
    "\n",
    "X_val = [X[item] for sublist in val_ind for item in sublist]\n",
    "y_val = [y[item] for sublist in val_ind for item in sublist]\n",
    "\n",
    "X_test = [X[item] for sublist in test_ind for item in sublist]\n",
    "y_test = [y[item] for sublist in test_ind for item in sublist]\n",
    "\n",
    "#train_indices, test_indices =train_test_split(indices,  test_size=0.2, shuffle=False)\n",
    "#indices = [item for sublist in indices for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d5bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs,  labels=None, pos=None):\n",
    "        self.tokenized_inputs = tokenized_inputs\n",
    "        self.labels = labels\n",
    "        self.pos = pos\n",
    "        self.id_list = None\n",
    "        self.re = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return {\n",
    "                \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
    "                \"labels_ids\": torch.tensor(self.labels[idx]),\n",
    "                #\"id\": torch.tensor(self.id_list[idx]),  # Include the id directly\n",
    "                #\"reservoir_ids\": torch.tensor(self.re[idx]),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
    "            }\n",
    "\n",
    "# Assuming you have X_train, y_train, X_test, y_test, trainpos, and testpos defined\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "val_dataset = CustomDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13806390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, gradient_accumulation_steps=1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "    def training_step(self, model, inputs):\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.n_gpu > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "        loss = loss / self.gradient_accumulation_steps\n",
    "        self.scaler.scale(loss).backward()\n",
    "\n",
    "        return loss.detach()\n",
    "\n",
    "\n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the training [`~torch.utils.data.DataLoader`].\n",
    "        Will use no sampler if `train_dataset` does not implement `__len__`, a random sampler (adapted to distributed\n",
    "        training if necessary) otherwise.\n",
    "        Subclass and override this method if you want to inject some custom behavior.\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "        train_dataset = self.train_dataset\n",
    "\n",
    "\n",
    "        loader =  DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self._train_batch_size,\n",
    "            drop_last=self.args.dataloader_drop_last,\n",
    "            shuffle = False,\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "#bert_model = TabularBertForSequenceClassification(config=configuration).to(\"cpu\", dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4d10de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8523, 'learning_rate': 4.984709480122324e-05, 'epoch': 0.46}\n",
      "{'eval_loss': 0.542745063399331, 'eval_r2_score': 0.3977828318093356, 'eval_mse': 0.5427450633993299, 'eval_runtime': 87.871, 'eval_samples_per_second': 8.558, 'eval_steps_per_second': 0.535, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5081, 'learning_rate': 4.9694189602446484e-05, 'epoch': 0.92}\n",
      "{'eval_loss': 0.44042871462086264, 'eval_r2_score': 0.5113106480460404, 'eval_mse': 0.44042871462086114, 'eval_runtime': 86.6465, 'eval_samples_per_second': 8.679, 'eval_steps_per_second': 0.542, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4953, 'learning_rate': 4.954128440366973e-05, 'epoch': 1.38}\n",
      "{'eval_loss': 0.40889913083821816, 'eval_r2_score': 0.5462951332864794, 'eval_mse': 0.40889913083821583, 'eval_runtime': 86.1331, 'eval_samples_per_second': 8.731, 'eval_steps_per_second': 0.546, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4202, 'learning_rate': 4.938837920489297e-05, 'epoch': 1.83}\n",
      "{'eval_loss': 0.3816474555080932, 'eval_r2_score': 0.5765329518360769, 'eval_mse': 0.3816474555080917, 'eval_runtime': 86.2798, 'eval_samples_per_second': 8.716, 'eval_steps_per_second': 0.545, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4282, 'learning_rate': 4.923547400611621e-05, 'epoch': 2.29}\n",
      "{'eval_loss': 0.360492618187818, 'eval_r2_score': 0.6000058622016868, 'eval_mse': 0.36049261818781747, 'eval_runtime': 87.4866, 'eval_samples_per_second': 8.596, 'eval_steps_per_second': 0.537, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3841, 'learning_rate': 4.9082568807339454e-05, 'epoch': 2.75}\n",
      "{'eval_loss': 0.3428670307565486, 'eval_r2_score': 0.6195627998255414, 'eval_mse': 0.34286703075654856, 'eval_runtime': 86.3546, 'eval_samples_per_second': 8.708, 'eval_steps_per_second': 0.544, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3748, 'learning_rate': 4.892966360856269e-05, 'epoch': 3.21}\n",
      "{'eval_loss': 0.345445995057762, 'eval_r2_score': 0.6167012416409043, 'eval_mse': 0.34544599505776225, 'eval_runtime': 86.4001, 'eval_samples_per_second': 8.704, 'eval_steps_per_second': 0.544, 'epoch': 3.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3489, 'learning_rate': 4.8776758409785936e-05, 'epoch': 3.67}\n",
      "{'eval_loss': 0.31995124631119004, 'eval_r2_score': 0.6449896157400294, 'eval_mse': 0.3199512463111893, 'eval_runtime': 86.171, 'eval_samples_per_second': 8.727, 'eval_steps_per_second': 0.545, 'epoch': 3.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3267, 'learning_rate': 4.862385321100918e-05, 'epoch': 4.13}\n",
      "{'eval_loss': 0.30166283278199413, 'eval_r2_score': 0.6652820096261589, 'eval_mse': 0.30166283278199457, 'eval_runtime': 84.3548, 'eval_samples_per_second': 8.915, 'eval_steps_per_second': 0.557, 'epoch': 4.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3098, 'learning_rate': 4.847094801223242e-05, 'epoch': 4.59}\n",
      "{'eval_loss': 0.2853782866950107, 'eval_r2_score': 0.6833509592879978, 'eval_mse': 0.2853782866950102, 'eval_runtime': 84.3344, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 4.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2805, 'learning_rate': 4.831804281345566e-05, 'epoch': 5.05}\n",
      "{'eval_loss': 0.2655988610356251, 'eval_r2_score': 0.705297745195968, 'eval_mse': 0.2655988610356249, 'eval_runtime': 84.3555, 'eval_samples_per_second': 8.915, 'eval_steps_per_second': 0.557, 'epoch': 5.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2805, 'learning_rate': 4.81651376146789e-05, 'epoch': 5.5}\n",
      "{'eval_loss': 0.25666265110997183, 'eval_r2_score': 0.7152131537343311, 'eval_mse': 0.2566626511099718, 'eval_runtime': 84.3573, 'eval_samples_per_second': 8.914, 'eval_steps_per_second': 0.557, 'epoch': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2444, 'learning_rate': 4.8012232415902144e-05, 'epoch': 5.96}\n",
      "{'eval_loss': 0.2435025160550307, 'eval_r2_score': 0.7298153303366488, 'eval_mse': 0.24350251605503107, 'eval_runtime': 84.316, 'eval_samples_per_second': 8.919, 'eval_steps_per_second': 0.557, 'epoch': 5.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2543, 'learning_rate': 4.785932721712538e-05, 'epoch': 6.42}\n",
      "{'eval_loss': 0.22892224994105884, 'eval_r2_score': 0.7459932509899077, 'eval_mse': 0.2289222499410594, 'eval_runtime': 84.331, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 6.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2184, 'learning_rate': 4.7706422018348626e-05, 'epoch': 6.88}\n",
      "{'eval_loss': 0.22247212651959006, 'eval_r2_score': 0.7531501563646497, 'eval_mse': 0.2224721265195903, 'eval_runtime': 84.3642, 'eval_samples_per_second': 8.914, 'eval_steps_per_second': 0.557, 'epoch': 6.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2332, 'learning_rate': 4.755351681957187e-05, 'epoch': 7.34}\n",
      "{'eval_loss': 0.2123292908809391, 'eval_r2_score': 0.7644044084392324, 'eval_mse': 0.2123292908809398, 'eval_runtime': 84.3403, 'eval_samples_per_second': 8.916, 'eval_steps_per_second': 0.557, 'epoch': 7.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1986, 'learning_rate': 4.740061162079511e-05, 'epoch': 7.8}\n",
      "{'eval_loss': 0.20612184473698716, 'eval_r2_score': 0.771292044809601, 'eval_mse': 0.20612184473698714, 'eval_runtime': 84.3152, 'eval_samples_per_second': 8.919, 'eval_steps_per_second': 0.557, 'epoch': 7.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2063, 'learning_rate': 4.724770642201835e-05, 'epoch': 8.26}\n",
      "{'eval_loss': 0.20909480743388845, 'eval_r2_score': 0.7679933152638163, 'eval_mse': 0.2090948074338881, 'eval_runtime': 84.3374, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 8.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1995, 'learning_rate': 4.709480122324159e-05, 'epoch': 8.72}\n",
      "{'eval_loss': 0.19486207595227015, 'eval_r2_score': 0.783785619655854, 'eval_mse': 0.19486207595227026, 'eval_runtime': 84.4384, 'eval_samples_per_second': 8.906, 'eval_steps_per_second': 0.557, 'epoch': 8.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1905, 'learning_rate': 4.694189602446483e-05, 'epoch': 9.17}\n",
      "{'eval_loss': 0.19783942922513667, 'eval_r2_score': 0.7804820184301535, 'eval_mse': 0.1978394292251368, 'eval_runtime': 84.5277, 'eval_samples_per_second': 8.896, 'eval_steps_per_second': 0.556, 'epoch': 9.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1884, 'learning_rate': 4.678899082568808e-05, 'epoch': 9.63}\n",
      "{'eval_loss': 0.18950217596995259, 'eval_r2_score': 0.7897328387220576, 'eval_mse': 0.18950217596995292, 'eval_runtime': 84.4839, 'eval_samples_per_second': 8.901, 'eval_steps_per_second': 0.556, 'epoch': 9.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1753, 'learning_rate': 4.663608562691132e-05, 'epoch': 10.09}\n",
      "{'eval_loss': 0.18469383750037927, 'eval_r2_score': 0.7950680580950589, 'eval_mse': 0.18469383750037918, 'eval_runtime': 84.4058, 'eval_samples_per_second': 8.909, 'eval_steps_per_second': 0.557, 'epoch': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1829, 'learning_rate': 4.648318042813456e-05, 'epoch': 10.55}\n",
      "{'eval_loss': 0.17945086460070556, 'eval_r2_score': 0.8008855376180708, 'eval_mse': 0.1794508646007063, 'eval_runtime': 84.3924, 'eval_samples_per_second': 8.911, 'eval_steps_per_second': 0.557, 'epoch': 10.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1621, 'learning_rate': 4.6330275229357804e-05, 'epoch': 11.01}\n",
      "{'eval_loss': 0.18473524978953326, 'eval_r2_score': 0.7950221079921754, 'eval_mse': 0.1847352497895333, 'eval_runtime': 84.3914, 'eval_samples_per_second': 8.911, 'eval_steps_per_second': 0.557, 'epoch': 11.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1797, 'learning_rate': 4.617737003058104e-05, 'epoch': 11.47}\n",
      "{'eval_loss': 0.18211496131747582, 'eval_r2_score': 0.7979295185056894, 'eval_mse': 0.18211496131747598, 'eval_runtime': 84.3639, 'eval_samples_per_second': 8.914, 'eval_steps_per_second': 0.557, 'epoch': 11.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1559, 'learning_rate': 4.602446483180428e-05, 'epoch': 11.93}\n",
      "{'eval_loss': 0.17901058433550857, 'eval_r2_score': 0.8013740622540326, 'eval_mse': 0.17901058433550915, 'eval_runtime': 84.3378, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 11.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1709, 'learning_rate': 4.587155963302753e-05, 'epoch': 12.39}\n",
      "{'eval_loss': 0.17514350880125407, 'eval_r2_score': 0.8056648783930725, 'eval_mse': 0.1751435088012548, 'eval_runtime': 84.3209, 'eval_samples_per_second': 8.918, 'eval_steps_per_second': 0.557, 'epoch': 12.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1484, 'learning_rate': 4.571865443425077e-05, 'epoch': 12.84}\n",
      "{'eval_loss': 0.1715689421466698, 'eval_r2_score': 0.8096311335530009, 'eval_mse': 0.17156894214666932, 'eval_runtime': 84.3462, 'eval_samples_per_second': 8.916, 'eval_steps_per_second': 0.557, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1617, 'learning_rate': 4.556574923547401e-05, 'epoch': 13.3}\n",
      "{'eval_loss': 0.17613893731026872, 'eval_r2_score': 0.804560374311396, 'eval_mse': 0.17613893731026825, 'eval_runtime': 84.3598, 'eval_samples_per_second': 8.914, 'eval_steps_per_second': 0.557, 'epoch': 13.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1479, 'learning_rate': 4.541284403669725e-05, 'epoch': 13.76}\n",
      "{'eval_loss': 0.16823347202776803, 'eval_r2_score': 0.8133320928155483, 'eval_mse': 0.16823347202776742, 'eval_runtime': 84.3385, 'eval_samples_per_second': 8.916, 'eval_steps_per_second': 0.557, 'epoch': 13.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1489, 'learning_rate': 4.525993883792049e-05, 'epoch': 14.22}\n",
      "{'eval_loss': 0.17094068658191777, 'eval_r2_score': 0.8103282311640505, 'eval_mse': 0.17094068658191786, 'eval_runtime': 84.3474, 'eval_samples_per_second': 8.916, 'eval_steps_per_second': 0.557, 'epoch': 14.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1442, 'learning_rate': 4.510703363914373e-05, 'epoch': 14.68}\n",
      "{'eval_loss': 0.16528397773707365, 'eval_r2_score': 0.8166047823692981, 'eval_mse': 0.1652839777370735, 'eval_runtime': 84.335, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 14.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1399, 'learning_rate': 4.4954128440366975e-05, 'epoch': 15.14}\n",
      "{'eval_loss': 0.16613993638464317, 'eval_r2_score': 0.8156550307684278, 'eval_mse': 0.1661399363846436, 'eval_runtime': 86.6452, 'eval_samples_per_second': 8.679, 'eval_steps_per_second': 0.542, 'epoch': 15.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1401, 'learning_rate': 4.480122324159022e-05, 'epoch': 15.6}\n",
      "{'eval_loss': 0.1635414166273624, 'eval_r2_score': 0.8185382872275776, 'eval_mse': 0.1635414166273617, 'eval_runtime': 87.59, 'eval_samples_per_second': 8.585, 'eval_steps_per_second': 0.537, 'epoch': 15.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1317, 'learning_rate': 4.4648318042813456e-05, 'epoch': 16.06}\n",
      "{'eval_loss': 0.1610296221701667, 'eval_r2_score': 0.821325315331739, 'eval_mse': 0.16102962217016695, 'eval_runtime': 86.0312, 'eval_samples_per_second': 8.741, 'eval_steps_per_second': 0.546, 'epoch': 16.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1361, 'learning_rate': 4.44954128440367e-05, 'epoch': 16.51}\n",
      "{'eval_loss': 0.1605348332533769, 'eval_r2_score': 0.8218743214865906, 'eval_mse': 0.1605348332533768, 'eval_runtime': 85.824, 'eval_samples_per_second': 8.762, 'eval_steps_per_second': 0.548, 'epoch': 16.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.128, 'learning_rate': 4.434250764525994e-05, 'epoch': 16.97}\n",
      "{'eval_loss': 0.15896376327344736, 'eval_r2_score': 0.8236175438171942, 'eval_mse': 0.1589637632734472, 'eval_runtime': 84.3418, 'eval_samples_per_second': 8.916, 'eval_steps_per_second': 0.557, 'epoch': 16.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1296, 'learning_rate': 4.418960244648318e-05, 'epoch': 17.43}\n",
      "{'eval_loss': 0.15586202722630688, 'eval_r2_score': 0.8270591572463141, 'eval_mse': 0.155862027226307, 'eval_runtime': 84.3214, 'eval_samples_per_second': 8.918, 'eval_steps_per_second': 0.557, 'epoch': 17.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1235, 'learning_rate': 4.403669724770643e-05, 'epoch': 17.89}\n",
      "{'eval_loss': 0.15687957978477268, 'eval_r2_score': 0.8259301048392662, 'eval_mse': 0.15687957978477263, 'eval_runtime': 84.334, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 17.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1248, 'learning_rate': 4.3883792048929664e-05, 'epoch': 18.35}\n",
      "{'eval_loss': 0.15777066256199163, 'eval_r2_score': 0.8249413803295311, 'eval_mse': 0.15777066256199218, 'eval_runtime': 84.3365, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 18.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.12, 'learning_rate': 4.373088685015291e-05, 'epoch': 18.81}\n",
      "{'eval_loss': 0.15462021421149597, 'eval_r2_score': 0.8284370437857472, 'eval_mse': 0.15462021421149605, 'eval_runtime': 84.2958, 'eval_samples_per_second': 8.921, 'eval_steps_per_second': 0.558, 'epoch': 18.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1213, 'learning_rate': 4.3577981651376146e-05, 'epoch': 19.27}\n",
      "{'eval_loss': 0.15550465017879694, 'eval_r2_score': 0.8274556944201024, 'eval_mse': 0.15550465017879678, 'eval_runtime': 84.3308, 'eval_samples_per_second': 8.917, 'eval_steps_per_second': 0.557, 'epoch': 19.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1166, 'learning_rate': 4.342507645259939e-05, 'epoch': 19.72}\n",
      "{'eval_loss': 0.15462937499869123, 'eval_r2_score': 0.8284268791915483, 'eval_mse': 0.15462937499869095, 'eval_runtime': 85.8352, 'eval_samples_per_second': 8.761, 'eval_steps_per_second': 0.548, 'epoch': 19.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1134, 'learning_rate': 4.327217125382263e-05, 'epoch': 20.18}\n",
      "{'eval_loss': 0.1576286455646956, 'eval_r2_score': 0.8250989590524247, 'eval_mse': 0.15762864556469502, 'eval_runtime': 86.7636, 'eval_samples_per_second': 8.667, 'eval_steps_per_second': 0.542, 'epoch': 20.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1136, 'learning_rate': 4.311926605504588e-05, 'epoch': 20.64}\n",
      "{'eval_loss': 0.15286608972215168, 'eval_r2_score': 0.8303833790983357, 'eval_mse': 0.15286608972215113, 'eval_runtime': 85.6131, 'eval_samples_per_second': 8.784, 'eval_steps_per_second': 0.549, 'epoch': 20.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1094, 'learning_rate': 4.2966360856269116e-05, 'epoch': 21.1}\n",
      "{'eval_loss': 0.1460408383200235, 'eval_r2_score': 0.8379565176651522, 'eval_mse': 0.14604083832002338, 'eval_runtime': 87.3519, 'eval_samples_per_second': 8.609, 'eval_steps_per_second': 0.538, 'epoch': 21.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"inputs_embeds\": torch.tensor(self.tokenized_inputs[idx]),\n",
      "C:\\Users\\Kowsher\\AppData\\Local\\Temp\\ipykernel_7224\\2303645629.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels_ids\": torch.tensor(self.labels[idx]),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m\n\u001b[0;32m     37\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     38\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results_task1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     39\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[0;32m     60\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     61\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)]\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 68\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1556\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1557\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1558\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1560\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1837\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1840\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1843\u001b[0m ):\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36mCustomTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics1(p):\n",
    "\n",
    "    preds = p.predictions.flatten()\n",
    "    labels = p.label_ids.flatten()\n",
    "\n",
    "    r2 = r2_score(labels, preds)\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    \n",
    "    return {\"r2_score\": r2, \"mse\": mse}\n",
    "\n",
    "def compute_metrics_classification(p):\n",
    "    preds = np.argmax(p.predictions , axis=1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {\"accuracy_score\": accuracy}\n",
    "\n",
    "def compute_metrics(p):\n",
    "    prediction_scores, labels_ids = p\n",
    "    #print('here')\n",
    "    #print(prediction_scores)\n",
    "\n",
    "    mask = labels_ids != 100\n",
    "    #print(mask)\n",
    "    masked_predictions = prediction_scores[mask]\n",
    "    masked_labels = labels_ids[mask]\n",
    "\n",
    "    mse = mean_squared_error(masked_predictions, masked_labels)\n",
    "    return {\"mse\": mse}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_task1',\n",
    "    num_train_epochs=150,\n",
    "    label_names=[\"labels_ids\"],\n",
    "    disable_tqdm = True,\n",
    "    #label_names=[\"labels_mask\"],\n",
    "    do_eval=True,\n",
    "    #learning_rate=0.001,\n",
    "    per_device_train_batch_size=batch,\n",
    "    per_device_eval_batch_size=batch,\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps = 50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics1, #compute_metrics1,#compute_metrics_classification,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac7d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reservoirtransformers.ReservoirTTimeSeries.from_pretrained(\"results_task1/checkpoint-2300\", config=configuration).to(\"cuda\", dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827f3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ln = len(X_test)\n",
    "y_pred = []\n",
    "y_test1 = []\n",
    "while cnt < ln:\n",
    "    #print(cnt, ln)\n",
    "    input_ids = torch.stack(X_test[cnt:cnt+batch], dim=0)\n",
    "    #y_test1 = y_test1 + [k.detach().numpy().flatten() for k in y_test[cnt:cnt+64]]\n",
    "    \n",
    "    output = model(inputs_embeds = input_ids.to(model.device))['logits']\n",
    "    y_pred = y_pred + list(output.cpu().detach().numpy().reshape(output.size(0), -1))\n",
    "    #y_test = y_test + labels_ids\n",
    "    \n",
    "    cnt=cnt+batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fae404b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19853861477957416"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "y_test1 = [i.detach().numpy().flatten() for i in y_test]\n",
    "\n",
    "mse = mean_squared_error(y_test1, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14f334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
